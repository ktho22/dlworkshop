{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 라이브러리 실습: Torch의 이해 및 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 실습 목표\n",
    "\n",
    "* Torch와 nn 패키지의 이해\n",
    "* 작은 Neural network 를 CPU에서 학습 및 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시작에 앞서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Torch는 `Lua` 를 사용하여 코딩함\n",
    "* `Lua`는 `Javascript`와 유사한 면을 지니며, 변수는 global이 default로, `local`이라는 키워드로 로컬변수 설정이 가능\n",
    "* 1-based indexing.\n",
    "* Function call `foo.bar()`는 Lua에서 `foo:bar()`로 쓰임\n",
    "* Python에서의 `import`, C에서 `include` 처럼 외부 라이브러리를 포함시키는 명령어는 `require`임\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lua: 기본 사용법\n",
    "#### Strings, numbers, and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = 'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b[1] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b[2] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i=1,#b do -- the # operator is the length operator in Lua\n",
    "    print(b[i]) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor(5,3) -- construct a 5x3 matrix, uninitialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.rand(5,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b=torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- matrix-matrix multiplication: syntax 1\n",
    "a*b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- matrix-matrix multiplication: syntax 2\n",
    "torch.mm(a,b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- matrix-matrix multiplication: syntax 3\n",
    "c=torch.Tensor(5,4)\n",
    "c:mm(a,b) -- store the result of a*b in c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) CUDA Tensors\n",
    ":cuda function 을 통해서 변수를 GPU로 보낼 수 있음\n",
    "\n",
    "본 실습에서 주어진 환경은 CPU 기반으로 작동되지 않음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'cutorch';\n",
    "a = a:cuda()\n",
    "b = b:cuda()\n",
    "c = c:cuda()\n",
    "c:mm(a,b) -- done on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Add two tensors\n",
    "https://github.com/torch/torch7/blob/master/doc/maths.md#res-torchaddres-tensor1-tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function addTensors(a,b)\n",
    "    return a --FIX ME\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.ones(5,2)\n",
    "b = torch.Tensor(2,5):fill(4)\n",
    "print(addTensors(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예상 결과:\n",
    "\n",
    "5 5\n",
    "\n",
    "5 5\n",
    "\n",
    "5 5\n",
    "\n",
    "5 5\n",
    "\n",
    "5 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "Torch 에서 Neural Net은 `nn` 이라는 패키지를 통해서 구축함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `module`은 Neural Net을 구성하는 기본 요소로, Layer, activation 등을 정의함\n",
    "* 각 `module`은 `containers`를 이용하여 보다 복잡한 구조로 설계가 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시로, 다음과 같은 네트워크를 만들어보겠습니다.\n",
    "![LeNet](http://fastml.com/images/cifar/lenet5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위 네트워크는 Yann Lecun이 제시한 `LeNet` 이라고 불리는 네트워크로, 최근에는 `Convolutional Neural Network (CNN)` 이라는 이름으로 불림\n",
    "* 간단한 feed-forward 구조를 가지며, 입력으로 이미지를 받아 일련의 레이어들의 연산을 거친 뒤 해당 이미지가 0~9중 어떤 숫자인 지 맞추는 역할을 수행함\n",
    "* 이런 경우, `nn.Sequential`을 이용하여 여러 레이어를 묶을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(1, 6, 5, 5)) -- 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems\n",
    "\n",
    "print('Lenet5\\n' .. net:__tostring());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Sequential`이외에 다른 Container 들은 다음과 같음\n",
    "![containers](https://raw.githubusercontent.com/soumith/ex/gh-pages/assets/nn_containers.png)\n",
    "\n",
    "* Torch의 강점 중 하나는 Automatic differentiation을 지원한다는 것임\n",
    "* `:forward(input)` 으로 입력에 대한 출력이 만들어지면, `:backward(input, gradient)` 가 각 neuron 에 대한 gradient를 chain rule을 이용해 계산함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = torch.rand(1,32,32) -- pass a random tensor as input to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = net:forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net:zeroGradParameters() -- zero the internal gradient buffers of the network (will come to this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradInput = net:backward(input, torch.rand(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(#gradInput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion: loss function 정의하기\n",
    "\n",
    "앞서 계산한 Gradient 값은 랜덤한 숫자에 대해서 Backward 연산을 합니다.\n",
    "\n",
    "이제는, 정해진 목표에 기반해 네트워크를 학습하는 방법에 대해 알아보겠습니다. 이 때, 정해진 목표를 측정하는 방법을 __loss function__ 이라고 합니다.\n",
    "\n",
    "__loss function__은 주어진 입력이 모델을 통과해서 나온 결과와 정답을 비교하여 측정하게 되며, 네트워크는 이를 줄여나가는 방향으로 학습하게 됩니다. \n",
    "\n",
    "Torch 에서는 loss function 을 이용해 neural network 를 학습할 때 automatic differentiation을 쓰고, 이는 `forward(input, target)`, `backward(input, target)`을 통해서 구현됩니다. 아래에서 loss function 을 이용한 예시를 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion() -- a negative log-likelihood criterion for multi-class classification\n",
    "criterion:forward(output, 3) -- let's say the groundtruth was class number: 3\n",
    "gradients = criterion:backward(output, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradInput = net:backward(input, gradients)\n",
    "print(gradInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 현재까지 배운 내용\n",
    "* 하나의 네트워크는 다양한 컨테이너 및 모듈로 생성 가능하며, 사용하는 컨테이너/모듈에 따라 연산도 다양해집니다.\n",
    "* 네트워크는 :forward 로 입력을 받아 출력을 내보냅니다.\n",
    "* Criterion은 네트워크의 loss를 의미하며, 해당 loss를 줄이는 방향으로 gradient 를 계산합니다. \n",
    "* Criterion으로부터 계산한 gradient를 이용해 net:backward를 이용해 네트워크의 파라미터들을 수정합니다. \n",
    "\n",
    "##### Missing details\n",
    "* 특정 레이어는 학습 가능한 파라미터를 가지고 있지 않습니다.\n",
    "* 학습되는 파라미터는 주로 .weight (혹은 .bias) 라는 필드에 값이 저장되어 있으며, pooling layer의 경우에는 따로 파라미터를 학습하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = nn.SpatialConvolution(1,3,2,2) -- learn 3 2x2 kernels\n",
    "print(m.weight) -- initially, the weights are randomly initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(m.bias) -- The operation in a convolution layer is: output = convolution(input,weight) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이처럼, 접근 가능한 필드 중에서 학습되는 또 다른 필드는 gradWeight와 gradBisa가 있슨비다.\n",
    "gradWeight는 각 레이어 내의 weight에 대한 gradient가, gradBias는 레이어 내의 bias에 대한 gradient가 저장되는 곳입니다.\n",
    "\n",
    "#### Training the network\n",
    "\n",
    "이제부터 네트워크를 직접 학습해보겠습니다. 이는 아래의 식을 따라 파라미터를 변경하는 것을 의미합니다.\n",
    "> weight = weight + learningRate * gradWeight [equation 1]\n",
    "\n",
    "위 업데이트는 네트워크의 파라미터를 바꿔 loss를 줄여나가는 역할을 하게 됩니다. 본 실습에서 쓰이는 방법은 Stochastic Gradient Descent (SGD) 입니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 Equation 1을 수행하기 위해서는 SGD를 수행하는 nn 내의 모듈을 이용해야 합니다. 이는 [__nn.StochasticGradient__] 으로 정의되어 있습니다. (https://github.com/torch/nn/blob/master/doc/training.md#stochasticgradientmodule-criterion).\n",
    "\n",
    "위 모듈은 :train(dataset)이라는 함수를 가지고 있어 주어진 dataset을 이용해 네트워크를 학습할 수 있습니다. 자세한 사용법은 아래에서 설명하겠습니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about data?\n",
    "\n",
    "이제 직접 네트워크를 학습하기에 앞서, 데이터를 어떻게 네트워크에 넣는 지에 대해서 설명하겠습니다. 이미지, 텍스트, 오디오, 비디오 등 다양한 형식의 입력이 가능하며, 이는 예를 들어 [__image.load__](https://github.com/torch/image#res-imageloadfilename-depth-tensortype), [__audio.load__](https://github.com/soumith/lua---audio#usage) 등이 이용될 수 있습니다. 보다 자세한 Data I/O에 관련해서는 https://github.com/torch/torch7/wiki/Cheatsheet#data-formats 페이지를 참고하시면 도움을 얻을 수 있습니다. \n",
    "\n",
    "본 실습을 위해서 이용되는 데이터셋은 CIFAR-10 이라는 데이터로, 다음과 같은 class를 가지고 있습니다. 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'.  \n",
    "\n",
    "각 이미지는 3x32x32의 사이즈를 지니며, 즉, RGB 의 3채널의 32x32 pixels 크기의 이미지를 의미합니다.\n",
    "![CIFAR-10 image](https://raw.githubusercontent.com/soumith/ex/gh-pages/assets/cifar10.png)\n",
    "\n",
    "해당 데이터셋은  50,000의 트레이닝 이미지와 10,000 장의 테스트 이미지를 포함하고 있습니다.\n",
    "\n",
    "__딥러닝을 이용한 데이터 분석 5 단계__\n",
    "1. 데이터 Load 및 normalization\n",
    "2. 모델 정의 (e.g. DNN, CNN, ...)\n",
    "3. Loss function 정의 (e.g. Euclidean distance, NLL, ...)\n",
    "4. 트레이닝 데이터로 모델 학습하기\n",
    "5. 테스트 데이터로 모델 테스트하기\n",
    "\n",
    "__1. 데이터 Load 및 normalization__\n",
    "\n",
    "앞서 말한 CIFAR-10을 직접 불러오겠습니다. 이는 사전에 다운로드 받아져있을 것이며, 아닌 경우 자동으로 다운 받아집니다. (다운을 새로 받는 경우, 몇 분의 시간이 소요됩니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'paths'\n",
    "if (not paths.filep(\"cifar10torchsmall.zip\")) then\n",
    "    os.execute('wget -c https://s3.amazonaws.com/torch7/data/cifar10torchsmall.zip')\n",
    "    os.execute('unzip cifar10torchsmall.zip')\n",
    "end\n",
    "trainset = torch.load('cifar10-train.t7')\n",
    "testset = torch.load('cifar10-test.t7')\n",
    "classes = {'airplane', 'automobile', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(#trainset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10 내의 이미지를 프린트해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itorch.image(trainset.data[100]) -- display the 100-th image in dataset. You can freely change this.\n",
    "print(classes[trainset.label[100]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 언급한 __nn.StochasticGradient__ 에 이용되기 위해서는, dataset에 다음과 같은 가공을 해야 합니다. [documentation](https://github.com/torch/nn/blob/master/doc/training.md#traindataset).\n",
    "1. 데이터셋이 :size() 함수를 지니고 있어야 합니다. \n",
    "2. 데이터셋은 [i] 로 indexing이 가능해야 합니다. \n",
    "\n",
    "위 두 사항은 다음과 같이 진행함으로 데이터셋을 변형할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- ignore setmetatable for now, it is a feature beyond the scope of this tutorial. It sets the index operator.\n",
    "setmetatable(trainset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.label[i]} \n",
    "                end}\n",
    ");\n",
    "trainset.data = trainset.data:double() -- convert the data from a ByteTensor to a DoubleTensor.\n",
    "\n",
    "function trainset:size() \n",
    "    return self.data:size(1) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(trainset:size()) -- just to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(trainset[33]) -- load sample number 33.\n",
    "itorch.image(trainset[33][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__이제 주어진 데이터를 normalization을 해야 합니다. 일반적으로 많이 쓰이는 방법은 zero mean unit variance 로, 말 그대로 주어진 데이터의 mean을 0으로 맞추고  stdev을 1로 조정하는 것입니다. __\n",
    "\n",
    "위 normalization을 하기에 앞서, tensor variable을 indexing 하는 방법에 대해서 간략히 소개하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redChannel = trainset.data[{ {}, {1}, {}, {}  }] -- this picks {all images, 1st channel, all vertical pixels, all horizontal pixels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(#redChannel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 예제에서, trainset.data 를 [{}] 로 indexing 하기 시작했으며, {}는 모든 elements, {i}는 i i 인덱스를 추출하는 것을 의미합니다. range를 indexing 하기 위해서는 {i1, i2} (where i2>i1) 처럼 작성하면 되며 이 경우 i1 부터 i2 까지의 elements를 반환합니다. \n",
    "\n",
    "__연습문제: 데이터의 150번째부터 300번째까지 데이터를 추출하시오.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- TODO: fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 위에서 말한 zero mean unit variance normalization을 수행하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean = {} -- store the mean, to normalize the test set in the future\n",
    "stdv  = {} -- store the standard-deviation for the future\n",
    "for i=1,3 do -- over each image channel\n",
    "    mean[i] = trainset.data[{ {}, {i}, {}, {}  }]:mean() -- mean estimation\n",
    "    print('Channel ' .. i .. ', Mean: ' .. mean[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction\n",
    "    \n",
    "    stdv[i] = trainset.data[{ {}, {i}, {}, {}  }]:std() -- std estimation\n",
    "    print('Channel ' .. i .. ', Standard Deviation: ' .. stdv[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ 2. 모델 정의하기__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제:** 위의 __Neural Networks__ 섹션에서 코드를 가져와 3 채널 이미지를 입력으로 하는 네트워크를 설계해보세요. \n",
    "Hint: 첫번째 레이어만 수정하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(3, 6, 5, 5)) -- 3 input image channels, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Loss function 정의하기__\n",
    "\n",
    "본 예제에서는 Log-likelihood classification loss를 사용하겠습니다. Log-likelihood loss는 대부분의 classificatin에 통용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. 네트워크 학습하기__\n",
    "\n",
    "먼저, __nn.StochasticGradient__ 객체를 정의하겠습니다. 그 후에 생성한 객체의 __:train__ function에 앞서 정의한 dataset을 입력으로 넣어 학습을 진행하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 5 -- just do 5 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer:train(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. 학습된 네트워크 테스트하기__\n",
    "\n",
    "축하합니다! 네트워크를 성공적으로 학습하셨습니다.\n",
    "\n",
    "이제 학습한 네트워크가 테스트 데이터 (학습 때 쓰이지 않은, 모델이 처음 보는 데이터)에 대해서도 좋은 성능을 낼 수 있는 지 평가해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classes[testset.label[100]])\n",
    "itorch.image(testset.data[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트레이닝 데이터에서 해주었던 것처럼, testset의 데이터를 normalization 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testset.data = testset.data:double()   -- convert from Byte tensor to Double tensor\n",
    "for i=1,3 do -- over each image channel\n",
    "    testset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction    \n",
    "    testset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- for fun, print the mean and standard-deviation of example-100\n",
    "horse = testset.data[100]\n",
    "print(horse:mean(), horse:std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로, 학습한 네트워크에 테스트 데이터를 입력으로 하여 예측 결과를 출력해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classes[testset.label[100]])\n",
    "itorch.image(testset.data[100])\n",
    "predicted = net:forward(testset.data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- the output of the network is Log-Probabilities. To convert them to probabilities, you have to take e^x \n",
    "print(predicted:exp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력된 결과로부터 네트워크가 각 클래스에 대해 예측한 확률 값을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i=1,predicted:size(1) do\n",
    "    print(classes[i], predicted[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 하나의 데이터가 아니라 테스트셋의 모든 이미지를 입력으로 하여 전체 정답율을 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i=1,10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(correct, 100*correct/10000 .. ' % ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10개의 클래스가 있다는 상황에서, random guess를 하면 10%의 성능이 나온다는 것을 감안하면 위의 성능은 네트워크가 `데이터와 레이블 사이의 관계`를 학습이 되었다는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_performance = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n",
    "for i=1,10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        class_performance[groundtruth] = class_performance[groundtruth] + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i=1,#classes do\n",
    "    print(classes[i], 100*class_performance[i]/1000 .. ' %')\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__이제 딥러닝을 이용해 데이터 분석 5단계를 종료했습니다.__\n",
    "\n",
    "1. 데이터 Load 및 normalization\n",
    "2. 모델 정의 (e.g. DNN, CNN, ...)\n",
    "3. Loss function 정의 (e.g. Euclidean distance, NLL, ...)\n",
    "4. 트레이닝 데이터로 모델 학습하기\n",
    "5. 테스트 데이터로 모델 테스트하기\n",
    "\n",
    "아래부터는 gpu enable 상태로 빌드된 Torch에서 이용이 가능합니다.\n",
    "\n",
    "#### cunn: neural networks on GPUs using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'cunn';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 cpu에서 정의된 net을 :cuda() 를 이용해 gpu에 올립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = net:cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마찬가지로, criterion 또한 gpu에 올립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = criterion:cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 또한 gpu에 올립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset.data = trainset.data:cuda()\n",
    "trainset.label = trainset.label:cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 앞서 cpu에서 한 것과 같이 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 5 -- just do 5 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer:train(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크가 작을수록 cpu와 gpu의 성능 차이가 크지 않습니다. 성능 차이를 확인하기 위해선 보다 큰 네트워크를 이용해 실험을 진행하면 이를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 실습 목표 (recap)\n",
    "\n",
    "* Torch와 nn 패키지의 이해\n",
    "* 작은 Neural network 를 CPU에서 학습 및 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다음 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build crazy graphs of networks: https://github.com/torch/nngraph\n",
    "* Train on imagenet with multiple GPUs: https://github.com/soumith/imagenet-multiGPU.torch\n",
    "* Train recurrent networks with LSTM on text: https://github.com/wojzaremba/lstm\n",
    "\n",
    "* More demos and tutorials: https://github.com/torch/torch7/wiki/Cheatsheet\n",
    "\n",
    "* Chat with developers of Torch: http://gitter.im/torch/torch7\n",
    "* Ask for help: http://groups.google.com/forum/#!forum/torch7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
