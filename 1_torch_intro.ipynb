{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 라이브러리 실습: Torch의 이해 및 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 실습 목표\n",
    "\n",
    "* Torch와 nn 패키지의 이해\n",
    "* 작은 Neural network 를 CPU에서 학습 및 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시작에 앞서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Torch는 `Lua` 를 사용하여 코딩함\n",
    "* `Lua`는 `Javascript`와 유사한 면을 지니며, 변수는 global이 default로, `local`이라는 키워드로 로컬변수 설정이 가능\n",
    "* 1-based indexing.\n",
    "* Function call `foo.bar()`는 Lua에서 `foo:bar()`로 쓰임\n",
    "* Python에서의 `import`, C에서 `include` 처럼 외부 라이브러리를 포함시키는 명령어는 `require`임\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Lua: 기본 사용법\n",
    "#### Strings, numbers, and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = 'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b[1] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b[2] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i=1,#b do -- the # operator is the length operator in Lua\n",
    "    print(b[i]) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor(5,3) -- construct a 5x3 matrix, uninitialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.6571  0.1667  0.8858\n",
       " 0.0547  0.6048  0.4849\n",
       " 0.3794  0.5189  0.1749\n",
       " 0.8338  0.9002  0.2758\n",
       " 0.0220  0.6223  0.7457\n",
       "[torch.DoubleTensor of size 5x3]\n",
       "\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(5,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b=torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.1616  1.3225  0.6878  0.6795\n",
       " 0.7125  0.8149  0.8241  0.5996\n",
       " 0.5274  0.7661  0.6579  0.6855\n",
       " 0.9630  1.4436  1.1609  1.2946\n",
       " 0.9472  1.0081  0.9542  0.6328\n",
       "[torch.DoubleTensor of size 5x4]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- matrix-matrix multiplication: syntax 1\n",
    "a*b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.1616  1.3225  0.6878  0.6795\n",
       " 0.7125  0.8149  0.8241  0.5996\n",
       " 0.5274  0.7661  0.6579  0.6855\n",
       " 0.9630  1.4436  1.1609  1.2946\n",
       " 0.9472  1.0081  0.9542  0.6328\n",
       "[torch.DoubleTensor of size 5x4]\n",
       "\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- matrix-matrix multiplication: syntax 2\n",
    "torch.mm(a,b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- matrix-matrix multiplication: syntax 3\n",
    "c=torch.Tensor(5,4)\n",
    "c:mm(a,b) -- store the result of a*b in c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) CUDA Tensors\n",
    ":cuda function 을 통해서 변수를 GPU로 보낼 수 있음\n",
    "\n",
    "본 실습에서 주어진 환경은 CPU 기반으로 작동되지 않음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"require 'cutorch';...\"]:1: module 'cutorch' not found:\n\tno field package.preload['cutorch']\n\tno file '/root/.luarocks/share/lua/5.1/cutorch.lua'\n\tno file '/root/.luarocks/share/lua/5.1/cutorch/init.lua'\n\tno file '/root/torch/install/share/lua/5.1/cutorch.lua'\n\tno file '/root/torch/install/share/lua/5.1/cutorch/init.lua'\n\tno file './cutorch.lua'\n\tno file '/root/torch/install/share/luajit-2.1.0-beta1/cutorch.lua'\n\tno file '/usr/local/share/lua/5.1/cutorch.lua'\n\tno file '/usr/local/share/lua/5.1/cutorch/init.lua'\n\tno file '/root/torch/install/lib/cutorch.so'\n\tno file '/root/.luarocks/lib/lua/5.1/cutorch.so'\n\tno file '/root/torch/install/lib/lua/5.1/cutorch.so'\n\tno file './cutorch.so'\n\tno file '/usr/local/lib/lua/5.1/cutorch.so'\n\tno file '/usr/local/lib/lua/5.1/loadall.so'\nstack traceback:\n\t[C]: in function 'require'\n\t[string \"require 'cutorch';...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/root/torch/install/share/lua/5.1/itorch/main.lua:209: in function </root/torch/install/share/lua/5.1/itorch/main.lua:173>\n\t/root/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/root/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/root/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/root/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/root/torch/install/share/lua/5.1/itorch/main.lua:381: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406670",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"require 'cutorch';...\"]:1: module 'cutorch' not found:\n\tno field package.preload['cutorch']\n\tno file '/root/.luarocks/share/lua/5.1/cutorch.lua'\n\tno file '/root/.luarocks/share/lua/5.1/cutorch/init.lua'\n\tno file '/root/torch/install/share/lua/5.1/cutorch.lua'\n\tno file '/root/torch/install/share/lua/5.1/cutorch/init.lua'\n\tno file './cutorch.lua'\n\tno file '/root/torch/install/share/luajit-2.1.0-beta1/cutorch.lua'\n\tno file '/usr/local/share/lua/5.1/cutorch.lua'\n\tno file '/usr/local/share/lua/5.1/cutorch/init.lua'\n\tno file '/root/torch/install/lib/cutorch.so'\n\tno file '/root/.luarocks/lib/lua/5.1/cutorch.so'\n\tno file '/root/torch/install/lib/lua/5.1/cutorch.so'\n\tno file './cutorch.so'\n\tno file '/usr/local/lib/lua/5.1/cutorch.so'\n\tno file '/usr/local/lib/lua/5.1/loadall.so'\nstack traceback:\n\t[C]: in function 'require'\n\t[string \"require 'cutorch';...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/root/torch/install/share/lua/5.1/itorch/main.lua:209: in function </root/torch/install/share/lua/5.1/itorch/main.lua:173>\n\t/root/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/root/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/root/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/root/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/root/torch/install/share/lua/5.1/itorch/main.lua:381: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406670"
     ]
    }
   ],
   "source": [
    "require 'cutorch';\n",
    "a = a:cuda()\n",
    "b = b:cuda()\n",
    "c = c:cuda()\n",
    "c:mm(a,b) -- done on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Add two tensors\n",
    "https://github.com/torch/torch7/blob/master/doc/maths.md#res-torchaddres-tensor1-tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function addTensors(a,b)\n",
    "    return a --FIX ME\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1  1\n",
       " 1  1\n",
       " 1  1\n",
       " 1  1\n",
       " 1  1\n",
       "[torch.DoubleTensor of size 5x2]\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5,2)\n",
    "b = torch.Tensor(2,5):fill(4)\n",
    "print(addTensors(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예상 결과:\n",
    "\n",
    "5 5\n",
    "\n",
    "5 5\n",
    "\n",
    "5 5\n",
    "\n",
    "5 5\n",
    "\n",
    "5 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "Torch 에서 Neural Net은 `nn` 이라는 패키지를 통해서 구축함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `module`은 Neural Net을 구성하는 기본 요소로, Layer, activation 등을 정의함\n",
    "* 각 `module`은 `containers`를 이용하여 보다 복잡한 구조로 설계가 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시로, 다음과 같은 네트워크를 만들어보겠습니다.\n",
    "![LeNet](http://fastml.com/images/cifar/lenet5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위 네트워크는 Yann Lecun이 제시한 `LeNet` 이라고 불리는 네트워크로, 최근에는 `Convolutional Neural Network (CNN)` 이라는 이름으로 불림\n",
    "* 간단한 feed-forward 구조를 가지며, 입력으로 이미지를 받아 일련의 레이어들의 연산을 거친 뒤 해당 이미지가 0~9중 어떤 숫자인 지 맞추는 역할을 수행함\n",
    "* 이런 경우, `nn.Sequential`을 이용하여 여러 레이어를 묶을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lenet5\n",
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> output]\n",
       "  (1): nn.SpatialConvolution(1 -> 6, 5x5)\n",
       "  (2): nn.ReLU\n",
       "  (3): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (4): nn.SpatialConvolution(6 -> 16, 5x5)\n",
       "  (5): nn.ReLU\n",
       "  (6): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (7): nn.View(400)\n",
       "  (8): nn.Linear(400 -> 120)\n",
       "  (9): nn.ReLU\n",
       "  (10): nn.Linear(120 -> 84)\n",
       "  (11): nn.ReLU\n",
       "  (12): nn.Linear(84 -> 10)\n",
       "  (13): nn.LogSoftMax\n",
       "}\t\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(1, 6, 5, 5)) -- 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems\n",
    "\n",
    "print('Lenet5\\n' .. net:__tostring());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Sequential`이외에 다른 Container 들은 다음과 같음\n",
    "![containers](https://raw.githubusercontent.com/soumith/ex/gh-pages/assets/nn_containers.png)\n",
    "\n",
    "* Torch의 강점 중 하나는 Automatic differentiation을 지원한다는 것임\n",
    "* `:forward(input)` 으로 입력에 대한 출력이 만들어지면, `:backward(input, gradient)` 가 각 neuron 에 대한 gradient를 chain rule을 이용해 계산함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = torch.rand(1,32,32) -- pass a random tensor as input to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = net:forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.3367\n",
       "-2.2515\n",
       "-2.3401\n",
       "-2.2413\n",
       "-2.3146\n",
       "-2.3253\n",
       "-2.2232\n",
       "-2.3606\n",
       "-2.2954\n",
       "-2.3480\n",
       "[torch.DoubleTensor of size 10]\n",
       "\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net:zeroGradParameters() -- zero the internal gradient buffers of the network (will come to this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradInput = net:backward(input, torch.rand(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  1\n",
       " 32\n",
       " 32\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#gradInput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion: loss function 정의하기\n",
    "\n",
    "앞서 계산한 Gradient 값은 랜덤한 숫자에 대해서 Backward 연산을 하였습니다. \n",
    "\n",
    "이제는, 정해진 목표에 기반해 네트워크를 학습하는 방법에 대해 알아보겠습니다. 이 때, 정해진 목표를 측정하는 방법을 __loss function__ 이라고 합니다.\n",
    "\n",
    "__loss function__은 주어진 입력이 모델을 통과해서 나온 결과와 정답을 비교하여 측정하게 되며, 네트워크는 이를 줄여나가는 방향으로 학습하게 됩니다. \n",
    "\n",
    "Torch 에서는 loss function 을 이용해 neural network 를 학습할 때 automatic differentiation을 쓰고, 이는 `forward(input, target)`, `backward(input, target)`을 통해서 구현됩니다. 아래에서 loss function 을 이용한 예시를 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion() -- a negative log-likelihood criterion for multi-class classification\n",
    "criterion:forward(output, 3) -- let's say the groundtruth was class number: 3\n",
    "gradients = criterion:backward(output, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,.,.) = \n",
       " Columns 1 to 9\n",
       " 0.001 *\n",
       "   0.0000  0.0000  0.0064 -0.0034  0.0222 -0.0123 -0.0250 -0.1552 -0.2749\n",
       "   0.0000  0.0000  0.0010  0.0025  0.0448 -0.0533 -0.1079  0.0266 -0.0638\n",
       "   0.0314 -0.0342 -0.0887 -0.0558 -0.0788  0.1295 -0.1936  0.1972 -0.5158\n",
       "  -0.0636 -0.0088 -0.0722  0.0245  0.2374  0.1335 -0.1191 -0.1928 -0.2319\n",
       "  -0.0112  0.0547  0.1198 -0.0510  0.3496  0.2724 -0.2398 -0.2248  0.0759\n",
       "   0.1714 -0.3804 -0.1301  0.1357 -0.1681  0.0385  0.0594 -0.7066 -0.6154\n",
       "  -0.0862  0.2322  0.1547 -0.0085 -0.0301 -0.2508 -0.9369  1.0051 -0.2201\n",
       "  -0.3127  0.2796  0.2464  0.4211 -0.1879  0.8131  0.3610  0.1312  0.0088\n",
       "  -0.3618  0.0073 -0.3862  0.0051 -0.2499  0.9336 -0.1383 -0.1411  0.8883\n",
       "   0.0160  0.1302 -0.2053  0.1279 -0.1254  0.0548  0.1580 -0.7327  0.7760\n",
       "   0.0958  0.2201 -0.0951 -0.3289  0.5926  1.3484  0.8806  0.0399 -0.4512\n",
       "   0.1015 -0.1064  0.1872  0.2620  0.2367 -0.3377  0.7931  0.2455  0.3611\n",
       "   0.1760 -0.1961  0.3262 -0.3808  0.8006  0.5785 -0.1917  1.7519 -0.6935\n",
       "   0.1469 -0.1854 -0.1871 -0.1419  0.0064 -1.1343  0.1354 -0.0574  1.3915\n",
       "   0.2363  0.0771  0.0250  0.3028  1.3099  0.1261  0.1876 -0.7287 -0.1022\n",
       "   0.1522 -0.0139  0.0469  0.1154 -0.0174  0.4508 -0.5272  0.7240  1.0093\n",
       "  -0.0175 -0.1119 -0.2332 -0.1136  0.2093  0.4373  0.3281  0.3438  0.0832\n",
       "   0.0283  0.1542  0.8971  0.1310  0.6466 -0.0627  0.6411  0.6713  1.6952\n",
       "   0.0655 -0.2182  0.4113 -0.1886  0.4877 -0.3610  0.5201 -0.0648 -0.4180\n",
       "   0.1417  0.2340  0.2369  0.0736  0.0115  0.0569 -0.6642  0.1820  0.1462\n",
       "   0.1828  0.3023 -0.2183 -0.7898 -0.2935 -0.2378 -0.5438 -0.2979  0.1307\n",
       "  -0.3195 -0.0808  0.2656 -0.4083  0.1439 -0.0718 -0.0532 -1.0741  0.3401\n",
       "  -0.0622 -0.0347  0.0207  0.4896 -0.3399  0.2107 -0.1606 -0.0564 -0.0113\n",
       "  -0.1765 -0.0815  0.4160  0.1120  0.2182 -0.1508 -0.3063 -0.6754 -0.9998\n",
       "  -0.1672  0.0208  0.3743  0.5270 -0.3398 -0.7684 -0.4955 -0.6419  0.3934\n",
       "  -0.2161  0.0144  0.3394 -0.1348  0.0338  0.1734 -0.2799 -0.7988 -0.3427\n",
       "  -0.0158 -0.0170  0.1189 -0.0938 -0.1147  0.0196 -0.2394 -0.1741 -0.2093\n",
       "  -0.0303 -0.0226  0.3426 -0.0117 -0.0741 -0.2680 -0.5582  0.2733  0.0200\n",
       "  -0.0496 -0.0257  0.1157  0.0296 -0.0078  0.0425  0.0625 -0.3281 -0.1689\n",
       "  -0.0524  0.0045  0.0818 -0.0528  0.0049 -0.1690 -0.2210 -0.1081  0.2021\n",
       "   0.0093  0.0287 -0.0516  0.0134  0.0349 -0.1444  0.1245 -0.1943  0.0789\n",
       "   0.0047 -0.0056  0.1636 -0.0661  0.1334 -0.1050  0.0351 -0.0656  0.0527\n",
       "\n",
       "Columns 10 to 18\n",
       " 0.001 *\n",
       "  -0.0856 -0.1014  0.0463  0.1808 -0.0099  0.2656  0.0726  0.1700  0.1005\n",
       "   0.0719 -0.0687 -0.0801 -0.2993 -0.4887  0.0439  0.3335 -0.0264  0.0842\n",
       "   0.1235 -0.3359  0.2408 -0.5758  0.5772  0.1233 -0.3564  0.2391  0.1869\n",
       "   0.6822 -0.1450  0.2927 -0.3708 -0.1092 -0.4661  0.0900  0.3914  0.7486\n",
       "  -0.6369 -0.2454 -0.7671  0.3621  0.2298 -0.5721 -1.1968 -0.2861 -1.5266\n",
       "   0.3456  0.1801 -0.2722 -0.2224 -0.9815 -0.1709  0.7205  0.0642 -0.3920\n",
       "   0.3861 -0.5595 -1.2078 -1.4297 -0.4289  0.0041 -1.3021  0.7684  1.4725\n",
       "  -0.0059  0.0183  0.3796  0.5971 -1.1487 -0.1220 -0.6592  0.9479 -0.2886\n",
       "  -0.0764 -0.6559  0.0452  0.2267  0.2427  0.9625 -0.9078 -0.8061 -0.6109\n",
       "  -0.1827 -0.4389  2.0111  0.6507  0.0175 -0.5564 -1.2446 -1.6398 -1.4379\n",
       "  -1.5292  1.3398  0.9623  2.2058 -2.2277 -0.0566 -0.4119  1.4794 -0.8484\n",
       "   0.9316 -1.2382 -0.4712  0.5069 -0.1194 -0.8147 -1.4582 -0.9878  0.0993\n",
       "   0.4950 -0.6993  0.3264 -0.1171  0.1020  0.5255  1.9351  0.9703  0.1783\n",
       "   0.2400  1.2115 -0.2548  0.4085 -0.3997 -0.6772  0.5592 -0.2618  0.0529\n",
       "  -0.3823  1.0280  0.6247  1.9844  1.9913 -0.9627 -0.5338  1.1011  0.6446\n",
       "   0.6483 -0.1696 -0.9409  0.9049 -0.1842 -2.2558  0.4229 -1.6122 -0.4243\n",
       "   0.8785 -1.7349 -0.3941 -0.3200  1.4309 -0.7576  0.1434  0.3478 -0.0780\n",
       "   1.9357 -1.9274 -0.1170  0.6217  0.8554  0.1350 -0.6058  0.6880 -0.2432\n",
       "  -0.8228  0.5264 -0.4064 -0.7619 -0.5351 -0.0348 -0.7324 -0.9307  1.5596\n",
       "   0.9748 -0.1385 -1.0430 -1.3246  1.6262  0.3459  0.3949  0.5798  2.6257\n",
       "  -0.7079  1.2570 -0.7284  0.4154  0.0682  0.2270  0.5154  0.3212 -2.1942\n",
       "  -0.9036 -0.8012 -0.5562  0.1730 -0.9213  0.6084  0.2345 -0.0799 -0.6701\n",
       "  -0.2471  0.9179  0.0073  0.6802  0."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6058 -2.0045  0.7628  0.3989 -0.3962\n",
       "   0.0431 -1.2270  1.1281  0.2448  0.8740  0.5779 -1.3741 -0.8918  0.0632\n",
       "   0.5204 -0.0664 -1.1703  0.5516  0.4615  1.2779 -0.3978 -0.7535  0.6822\n",
       "  -0.6239  0.1422 -0.7252 -0.2668  0.3064 -0.0139 -0.4357 -1.5841  0.2198\n",
       "  -0.0137  0.5591 -0.8692  0.2715  0.3483 -0.2814 -0.0496  0.3855 -0.4447\n",
       "  -0.1166  0.0274 -0.1221  0.0528  0.3126  0.0811 -0.1265  0.6553 -0.0954\n",
       "  -0.2806 -0.1834 -0.3654  0.7583  0.5998 -0.1831 -0.4696 -0.4084 -1.5565\n",
       "   0.2116  0.0759  0.1503 -0.1352 -0.3760  0.4178  0.3543  0.4636  0.6674\n",
       "  -0.1484  0.0002 -0.0881  0.4206 -0.0214 -0.3512  0.2263  0.4329 -0.1132\n",
       "  -0.0084  0.0823 -0.0957  0.0036 -0.1772  0.2778 -0.1713  0.4491 -0.0718\n",
       "\n",
       "Columns 19 to 27\n",
       " 0.001 *\n",
       "   0.0429 -0.0516  0.0297  0.0046  0.1510 -0.0801  0.2348  0.0151  0.0563\n",
       "  -0.2034  0.0328 -0.0163 -0.0309 -0.1395  0.1169  0.2487  0.0142  0.1513\n",
       "   0.0078 -0.0863  0.2858 -0.4961  0.2984 -0.2500 -0.1216  0.1621 -0.0773\n",
       "   0.7146 -0.3406 -0.5850 -0.1363 -0.1907  0.3353  0.3921  0.3741  0.1606\n",
       "  -0.2357  0.4984  0.2683 -0.8438 -0.6800 -0.1009 -0.2085  0.0875 -0.2469\n",
       "   0.3713 -0.6902  0.4225 -0.1262 -0.2185 -0.1886 -0.3350  0.0550  0.2942\n",
       "   1.0999 -0.0414  0.6636  0.7132  0.8231 -0.4799  0.5193 -0.4374 -0.5877\n",
       "   0.7359 -1.4814  0.4592 -0.5943 -0.3112 -0.7358 -0.2749 -0.3565 -0.3848\n",
       "  -0.2475 -0.7157  0.4198  1.4787 -0.2374  0.4247  1.0064 -0.3348  0.4214\n",
       "  -0.5187  0.1796 -0.1032 -0.4811  0.7457 -0.5484 -0.4063 -0.2819 -0.2009\n",
       "   0.1664 -1.4887 -0.3837 -0.9746 -1.4528  0.8513 -1.0473  0.0710 -0.0074\n",
       "   0.0636 -0.9398  1.1980  1.4954  0.2198 -0.3834 -1.7537 -0.1601 -0.9546\n",
       "   0.6409 -0.7194 -0.5239 -0.5409 -0.1881  0.4143  1.1153 -0.0060 -0.1205\n",
       "  -0.3175 -1.5719  2.3378  1.1437 -0.0474  0.1268 -0.9354  0.9052 -0.3046\n",
       "  -0.2486  0.7245 -0.2473 -0.2011 -1.1322  0.7940 -0.5833  0.2265  0.0793\n",
       "  -0.1811  0.4753  1.3398  0.9013  1.3694  1.1447  0.1793 -0.6206 -0.2438\n",
       "  -1.0761 -1.0086 -0.3775  0.9836 -0.5457  1.5401  0.1214 -0.1423 -0.2394\n",
       "  -0.9459  0.0557  1.1416  0.6138 -0.1389  0.7260 -1.7974 -0.4387 -0.5486\n",
       "   0.2057 -0.6275 -0.7495 -0.5371 -0.9602  1.0601 -0.2130  0.0321 -0.5322\n",
       "  -3.1755 -0.5624  0.1775 -0.9646 -0.1786  0.9149 -0.1676  0.2211  0.2097\n",
       "   2.6777  0.0242  0.1951 -1.0734 -0.6613 -1.4002 -0.3901 -0.4604  0.7391\n",
       "   2.6629 -1.4909 -0.2323  0.4796 -1.0239  0.1054  0.3394 -0.3589 -1.1095\n",
       "   0.0437  1.9152 -1.0513  1.0838 -1.0502 -0.1265 -0.9600 -0.0387 -0.1985\n",
       "   1.2225  0.9353 -0.9085  0.5678 -0.5682  0.2376 -0.7356  0.2208 -0.5838\n",
       "  -0.9097  0.4020  0.4602  0.1368  0.8542 -0.2544 -0.4669  0.6930  0.2463\n",
       "   0.1283 -0.4598  0.4220 -0.3125 -0.3332 -0.6691  0.3863 -0.6832 -0.0710\n",
       "   0.0675 -0.5309  0.2440  1.2315  1.2323  0.7323  0.9313 -0.0160  0.0145\n",
       "   0.6248 -0.0790  0.9693 -1.1131  0.0682 -0.7151  0.3496  0.0077  0.3605\n",
       "  -0.0830 -0.5040  0.5148  0.1025  0.7145 -0.1248  0.2779 -0.3941  0.2880\n",
       "  -0.7577  0.8115  0.5604  0.2823  0.6045  0.1106  0.3086 -0.9583 -0.0269\n",
       "  -0.2486 -0.1961 -0.1994 -0.2338 -0.4592  0.9356  0.4002 -0.2264  0.0488\n",
       "   0.2679  0.1772  0.2536 -0.5784  0.3920 -0.3562  0.4655 -0.1417 -0.0697\n",
       "\n",
       "Columns 28 to 32\n",
       " 0.001 *\n",
       "  -0.0164 -0.0431  0.0092 -0.0050  0.0000\n",
       "  -0.0962  0.0121 -0.0619  0.1066 -0.0561\n",
       "  -0.1041  0.0881 -0.1272  0.0084 -0.0759\n",
       "   0.1635  0.1879 -0.0160  0.0606  0.0577\n",
       "  -0.0726  0.1116  0.0672 -0.0619  0.1108\n",
       "   0.5097 -0.0981  0.2987 -0.1981  0.1543\n",
       "   0.2964  0.3283  0.1583  0.1827 -0.1587\n",
       "  -0.2941  0.4350 -0.0671  0.3832  0.1687\n",
       "  -0.5455  0.0890 -0.2613  0.0398 -0.0218\n",
       "   0.5922  0.0046  0.1565 -0.0910  0.1481\n",
       "  -0.5409  0.2087  0.0092  0.0212  0.1704\n",
       "   0.3851  0.1092  0.3844  0.3562 -0.3998\n",
       "  -1.0946  0.5679 -0.3996  0.3275  0.2776\n",
       "  -0.5472 -0.4581 -0.5145 -0.0747 -0.0160\n",
       "   1.0892  0.0723 -0.0825  0.2598 -0.2940\n",
       "  -1.3880 -0.9341  0.6982 -0.2941  0.1129\n",
       "   0.5705 -0.5187  0.3000 -0.3126 -0.2500\n",
       "   0.1753 -0.1228  0.3045  0.2505  0.1641\n",
       "  -0.5285  0.6779 -0.0958 -0.0822 -0.0404\n",
       "   0.4695  0.2320  0.1107  0.3277  0.1328\n",
       "   0.0748 -0.4218  0.2515 -0.1117  0.1317\n",
       "  -0.1481 -0.1035  0.4057 -0.0198 -0.1325\n",
       "  -0.3279  0.2712 -0.1265  0.0187 -0.1492\n",
       "  -0."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9995 -0.1176 -0.1310 -0.1252  0.1268\n",
       "  -0.1927  0.0007  0.1390 -0.0497 -0.2600\n",
       "  -0.1046 -0.3284  0.2408  0.0828  0.0704\n",
       "  -0.1751 -0.0969  0.0167  0.0165  0.0206\n",
       "   0.6408  0.0376 -0.2914  0.0127 -0.0684\n",
       "  -0.0108 -0.1577  0.3018  0.0038  0.0843\n",
       "   0.6238 -0.2272 -0.0282  0.0077  0.0100\n",
       "  -0.0317 -0.0866  0.1328  0.0000  0.0000\n",
       "   0.1779 -0.0737  0.1008  0.0000  0.0000\n",
       "[torch.DoubleTensor of size 1x32x32]\n",
       "\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradInput = net:backward(input, gradients)\n",
    "print(gradInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 현재까지 배운 내용\n",
    "* 하나의 네트워크는 다양한 컨테이너 및 모듈로 생성 가능하며, 사용하는 컨테이너/모듈에 따라 연산도 다양해집니다.\n",
    "* 네트워크는 :forward 로 입력을 받아 출력을 내보냅니다.\n",
    "* Criterion은 네트워크의 loss를 의미하며, 해당 loss를 줄이는 방향으로 gradient 를 계산합니다. \n",
    "* Criterion으로부터 계산한 gradient를 이용해 net:backward를 이용해 네트워크의 파라미터들을 수정합니다. \n",
    "\n",
    "##### Missing details\n",
    "> A neural network layer can have learnable parameters or not.\n",
    "\n",
    "A convolution layer learns it's convolution kernels to adapt to the input data and the problem being solved.  \n",
    "A max-pooling layer has no learnable parameters. It only finds the max of local windows.\n",
    "\n",
    "A layer in torch which has learnable weights, will typically have fields .weight (and optionally, .bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,1,.,.) = \n",
       "  0.0609  0.0852\n",
       " -0.1986 -0.1194\n",
       "\n",
       "(2,1,.,.) = \n",
       "  0.4351 -0.4792\n",
       " -0.2842  0.0821\n",
       "\n",
       "(3,1,.,.) = \n",
       "  0.2197  0.3140\n",
       "  0.3606 -0.1833\n",
       "[torch.DoubleTensor of size 3x1x2x2]\n",
       "\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.SpatialConvolution(1,3,2,2) -- learn 3 2x2 kernels\n",
    "print(m.weight) -- initially, the weights are randomly initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2446\n",
       " 0.4891\n",
       " 0.3018\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m.bias) -- The operation in a convolution layer is: output = convolution(input,weight) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also two other important fields in a learnable layer. The gradWeight and gradBias.\n",
    "The gradWeight accumulates the gradients w.r.t. each weight in the layer, and the gradBias, w.r.t. each bias in the layer.\n",
    "\n",
    "#### Training the network\n",
    "\n",
    "For the network to adjust itself, it typically does this operation (if you do Stochastic Gradient Descent):\n",
    "> weight = weight + learningRate * gradWeight [equation 1]\n",
    "\n",
    "This update over time will adjust the network weights such that the output loss is decreasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now it is time to discuss one missing piece. Who visits each layer in your neural network and updates the weight according to Equation 1?\n",
    "\n",
    "There are multiple answers, but we will use the simplest answer.  \n",
    "We shall use the simple SGD trainer shipped with the neural network module: [__nn.StochasticGradient__](https://github.com/torch/nn/blob/master/doc/training.md#stochasticgradientmodule-criterion).\n",
    "\n",
    "It has a function :train(dataset) that takes a given dataset and simply trains your network by showing different samples from your dataset to the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about data?\n",
    "Generally, when you have to deal with image, text, audio or video data, you can use standard functions like: [__image.load__](https://github.com/torch/image#res-imageloadfilename-depth-tensortype) or [__audio.load__](https://github.com/soumith/lua---audio#usage) to load your data into a _torch.Tensor_ or a Lua table, as convenient.\n",
    "\n",
    "Let us now use some simple data to train our network.\n",
    "\n",
    "We shall use the CIFAR-10 dataset, which has the classes: 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'.  \n",
    "The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "![CIFAR-10 image](https://raw.githubusercontent.com/soumith/ex/gh-pages/assets/cifar10.png)\n",
    "\n",
    "The dataset has 50,000 training images and 10,000 test images in total.\n",
    "\n",
    "__We now have 5 steps left to do in training our first torch neural network__\n",
    "1. Load and normalize data\n",
    "2. Define Neural Network\n",
    "3. Define Loss function\n",
    "4. Train network on training data\n",
    "5. Test network on test data.\n",
    "\n",
    "__1. Load and normalize data__\n",
    "\n",
    "Today, in the interest of time, we prepared the data before-hand into a 4D torch ByteTensor of size 50000x3x32x32 (training) and 10000x3x32x32 (testing)\n",
    "Let us load the data and inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'paths'\n",
    "if (not paths.filep(\"cifar10torchsmall.zip\")) then\n",
    "    os.execute('wget -c https://s3.amazonaws.com/torch7/data/cifar10torchsmall.zip')\n",
    "    os.execute('unzip cifar10torchsmall.zip')\n",
    "end\n",
    "trainset = torch.load('cifar10-train.t7')\n",
    "testset = torch.load('cifar10-test.t7')\n",
    "classes = {'airplane', 'automobile', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  data : ByteTensor - size: 10000x3x32x32\n",
       "  label : ByteTensor - size: 10000\n",
       "}\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10000\n",
       "     3\n",
       "    32\n",
       "    32\n",
       "[torch.LongStorage of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#trainset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun, let us display an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "automobile\t\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "itorch.image(trainset.data[100]) -- display the 100-th image in dataset\n",
    "print(classes[trainset.label[100]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to prepare the dataset to be used with __nn.StochasticGradient__, a couple of things have to be done according to it's [documentation](https://github.com/torch/nn/blob/master/doc/training.md#traindataset).\n",
    "1. The dataset has to have a :size() function.\n",
    "2. The dataset has to have a [i] index operator, so that dataset[i] returns the ith sample in the datset.\n",
    "\n",
    "Both can be done quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- ignore setmetatable for now, it is a feature beyond the scope of this tutorial. It sets the index operator.\n",
    "setmetatable(trainset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.label[i]} \n",
    "                end}\n",
    ");\n",
    "trainset.data = trainset.data:double() -- convert the data from a ByteTensor to a DoubleTensor.\n",
    "\n",
    "function trainset:size() \n",
    "    return self.data:size(1) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainset:size()) -- just to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 3x32x32\n",
       "  2 : 2\n",
       "}\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(trainset[33]) -- load sample number 33.\n",
    "itorch.image(trainset[33][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__One of the most important things you can do in conditioning your data (in general in data-science or machine learning) is to make your data to have a mean of 0.0 and standard-deviation of 1.0.__\n",
    "\n",
    "Let us do that as a final step of our data processing.\n",
    "\n",
    "To do this, we introduce you to the tensor indexing operator.\n",
    "It is shown by example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redChannel = trainset.data[{ {}, {1}, {}, {}  }] -- this picks {all images, 1st channel, all vertical pixels, all horizontal pixels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10000\n",
       "     1\n",
       "    32\n",
       "    32\n",
       "[torch.LongStorage of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#redChannel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this indexing operator, you initally start with ___[{ }]___. You can pick all elements in a dimension using ___{}___ or pick a particular element using ___{i}___ where ___i___ is the element index. You can also pick a range of elements using ___{i1, i2}___, for example ___{3,5}___ gives us the 3,4,5 elements.\n",
    "\n",
    "__Exercise: Select the 150th to 300th data elements of the data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- TODO: fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving back to mean-subtraction and standard-deviation based scaling, doing this operation is simple, using the indexing operator that we learnt above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Channel 1, Mean: 125.83175029297\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 1, Standard Deviation: 63.143400842609\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 2, Mean: 123.26066621094\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 2, Standard Deviation: 62.369209019002\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 3, Mean: 114.03068681641\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 3, Standard Deviation: 66.965808411114\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = {} -- store the mean, to normalize the test set in the future\n",
    "stdv  = {} -- store the standard-deviation for the future\n",
    "for i=1,3 do -- over each image channel\n",
    "    mean[i] = trainset.data[{ {}, {i}, {}, {}  }]:mean() -- mean estimation\n",
    "    print('Channel ' .. i .. ', Mean: ' .. mean[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction\n",
    "    \n",
    "    stdv[i] = trainset.data[{ {}, {i}, {}, {}  }]:std() -- std estimation\n",
    "    print('Channel ' .. i .. ', Standard Deviation: ' .. stdv[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you notice, our training data is now normalized and ready to be used.\n",
    "\n",
    "__ 2. Time to define our neural network__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Copy the neural network from the __Neural Networks__ section above and modify it to take 3-channel images (instead of 1-channel images as it was defined).  \n",
    "Hint: You only have to change the first layer, change the number 1 to be 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(3, 6, 5, 5)) -- 3 input image channels, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Let us define the Loss function__\n",
    "\n",
    "Let us use a Log-likelihood classification loss. It is well suited for most classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Train the neural network__\n",
    "\n",
    "This is when things start to get interesting.  \n",
    "Let us first define an __nn.StochasticGradient__ object. Then we will give our dataset to this object's ___:train___ function, and that will get the ball rolling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 5 -- just do 5 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  VolumetricMaxUnpooling : table: 0x40701818\n",
       "  ConcatTable : table: 0x4070ae18\n",
       "  MV : table: 0x41014208\n",
       "  SpatialAveragePooling : table: 0x407a1048\n",
       "  SpatialConvolutionMM : table: 0x4078e150\n",
       "  Reshape : table: 0x40d52bb8\n",
       "  Jacobian : \n",
       "    {\n",
       "      forward : function: 0x4101c458\n",
       "      testAllUpdate : function: 0x4101c5d8\n",
       "      testDiagHessianInput : function: 0x4101c558\n",
       "      testDiagHessianWeight : function: 0x4101c578\n",
       "      testDiagHessianBias : function: 0x4101c598\n",
       "      testDiagHessian : function: 0x4101c538\n",
       "      testJacobian : function: 0x4101c4d8\n",
       "      testIO : function: 0x4101c5b8\n",
       "      testJacobianUpdateParameters : function: 0x4101c518\n",
       "      backwardDiagHessian : function: 0x4101c478\n",
       "      testJacobianParameters : function: 0x4101c4f8\n",
       "      backwardUpdate : function: 0x4101c438\n",
       "      forwardUpdate : function: 0x4101c4b8\n",
       "      backward : function: 0x4101c3e0\n",
       "      linearModuleDiagHessian : function: 0x4101c498\n",
       "    }\n",
       "  SparseLinear : table: 0x41f29df8\n",
       "  SoftMarginCriterion : table: 0x418e82f0\n",
       "  SpatialCrossMapLRN : table: 0x402ad268\n",
       "  CAddTable : table: 0x41f3f490\n",
       " "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " TemporalConvolution : table: 0x407a3500\n",
       "  PairwiseDistance : table: 0x407ed8f8\n",
       "  WeightedMSECriterion : table: 0x41007200\n",
       "  SmoothL1Criterion : table: 0x418e5538\n",
       "  TemporalSubSampling : table: 0x407a4200\n",
       "  PartialLinear : table: 0x41e6bd10\n",
       "  TanhShrink : table: 0x41e367b0\n",
       "  MixtureTable : table: 0x407143d8\n",
       "  MSECriterion : table: 0x418e3dd0\n",
       "  LogSoftMax : table: 0x41e2dd00\n",
       "  Identity : table: 0x40719e88\n",
       "  Exp : table: 0x4199bd98\n",
       "  Add : table: 0x419959d8\n",
       "  SpatialConvolutionLocal : table: 0x41795c38\n",
       "  Squeeze : table: 0x4004eb18\n",
       "  AbsCriterion : table: 0x418e99e0\n",
       "  MultiCriterion : table: 0x418f2468\n",
       "  Max : table: 0x418dc500\n",
       "  MulConstant : table: 0x41e74b50\n",
       "  NarrowTable : table: 0x40718c98\n",
       "  View : table: 0x40f87768\n",
       "  VolumetricConvolution : table: 0x402ba798\n",
       "  SpatialSubSampling : table: 0x40794558\n",
       "  HardTanh : table: 0x41e29ef8\n",
       "  DistKLDivCriterion : table: 0x418f0938\n",
       "  SplitTable : table: 0x4070c120\n",
       "  DotProduct : table: 0x407f2030\n",
       "  HingeEmbeddingCriterion : table: 0x418f6a88\n",
       "  SpatialBatchNormalization : table: 0x402b6810\n",
       "  DepthConcat : table: 0x41584ce0\n",
       "  CMulTable : table: 0x41582270\n",
       "  SpatialAdaptiveMaxPooling : table: 0x407a2760\n",
       "  Parallel : table: 0x418d7f18\n",
       "  SoftShrink : table: 0x4177c330\n",
       "  SpatialSubtractiveNormalization : table: 0x402a4638\n",
       "  Log : table: 0x41e288d0\n",
       "  VolumetricDropout : table: 0x41a1a020\n",
       "  SpatialDropout : table: 0x41f4b468\n",
       "  LeakyReLU : table: 0x41782630\n",
       "  VolumetricMaxPooling : table: 0x402b0c60\n",
       "  hessian : \n",
       "    {\n",
       "      enable : function: 0x41017718\n",
       "    }\n",
       "  Linear : table: 0x40050570\n",
       "  Euclidean : table: 0x41580170\n",
       "  CriterionTable : table: 0x40715110\n",
       "  SpatialMaxPooling : table: 0x407971a8\n",
       "  MaskedSelect : table: 0x40d631d0\n",
       "  MultiMarginCriterion : table: 0x418fdcb8\n",
       "  ELU : table: 0x41786c78\n",
       "  Threshold : table: 0x4177e0e0\n",
       "  SpatialReflectionPadding : table: 0x402b1c90\n",
       "  Copy : table: 0x4199ab80\n",
       "  Unsqueeze : table: 0x41e6dd10\n",
       "  VolumetricAveragePooling : table: 0x40703880\n",
       "  StochasticGradient : table: 0x4100ecc8\n",
       "  SpatialContrastiveNormalization : table: 0x402a9688\n",
       "  Bilinear : table: 0x41f2bed8\n",
       "  SpatialReplicationPadding : table: 0x402b40f0\n",
       "  Padding : table: 0x41e76978\n",
       "  Container : table: 0x400553f0\n",
       "  MarginRankingCriterion : table: 0x418fbfa0\n",
       "  Module : table: 0x41e66510\n",
       "  VolumetricFullConvolution : table: 0x402a1ef0\n",
       "  Concat : table: 0x41f27610\n",
       "  CrossEntropyCriterion : table: 0x4100aaf0\n",
       "  LookupTable : table: 0x4178b4a8\n",
       "  MarginCriterion : table: 0x418e6cc0\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  HardShrink : table: 0x4177adb8\n",
       "  Abs : table: 0x41e37a08\n",
       "  SparseJacobian : \n",
       "    {\n",
       "      forward : function: 0x41020d60\n",
       "      testJacobian : function: 0x41020da0\n",
       "      testIO : function: 0x41020e00\n",
       "      testAllUpdate : function: 0x41020e20\n",
       "      testJacobianParameters : function: 0x41020dc0\n",
       "      testJacobianUpdateParameters : function: 0x41020de0\n",
       "      forwardUpdate : function: 0x41020d80\n",
       "      backward : function: 0x41020ce8\n",
       "      backwardUpdate : function: 0x41020d40\n",
       "    }\n",
       "  SoftMin : table: 0x41e31710\n",
       "  WeightedEuclidean : table: 0x41f3bab8\n",
       "  VolumetricBatchNormalization : table: 0x407045e8\n",
       "  ClassSimplexCriterion : table: 0x418eed08\n",
       "  Contiguous : table: 0x4199ceb0\n",
       "  FlattenTable : table: 0x407171a8\n",
       "  PReLU : table: 0x41780ec0\n",
       "  utils : \n",
       "    {\n",
       "      contiguousView : function: 0x415845e0\n",
       "      recursiveType : function: 0x41996e20\n",
       "      recursiveCopy : function: 0x415844d8\n",
       "      recursiveResizeAs : function: 0x40d5e298\n",
       "      recursiveAdd : function: 0x40d5e260\n",
       "      clear : function: 0x40d5e2d8\n",
       "      addSingletonDimension : function: 0x415845c0\n",
       "      recursiveFill : function: 0x40d5e2b8\n",
       "    }\n",
       "  JoinTable : table: 0x4070e9c0\n",
       "  ClassNLLCriterion : table: 0x418ebb28\n",
       "  CMul : table: 0x4157d508\n",
       "  CosineDistance : table: 0x407f06b0\n",
       "  Index : table: 0x419a2330\n",
       "  Mean : table: 0x41991b88\n",
       "  Dropout : table: 0x41f3e440\n",
       "  SoftPlus : table: 0x41e32bf0\n",
       "  SpatialDivisiveNormalization : table: 0x402a8598\n",
       "  L1Penalty : table: 0x418f6210\n",
       "  test : function: 0x40b76648\n",
       "  Power : table: 0x41e38dd8\n",
       "  Sqrt : table: 0x4199b878\n",
       "  Sequential : table: 0x41f0db58\n",
       "  MM : table: 0x41011590\n",
       "  ParallelCriterion : table: 0x4100cc90\n",
       "  Square : table: 0x41e3a160\n",
       "  BCECriterion : table: 0x410094e0\n",
       "  L1Cost : table: 0x418f6ea8\n",
       "  MultiLabelSoftMarginCriterion : table: 0x419009b0\n",
       "  MultiLabelMarginCriterion : table: 0x418ff028\n",
       "  SoftMax : table: 0x41e30208\n",
       "  CosineEmbeddingCriterion : table: 0x418fa3a0\n",
       "  Cosine : table: 0x407ee8b0\n",
       "  Clamp : table: 0x41e2aea0\n",
       "  L1HingeEmbeddingCriterion : table: 0x418f3fa8\n",
       "  SelectTable : table: 0x407101a8\n",
       "  CDivTable : table: 0x41f3e248\n",
       "  TemporalMaxPooling : table: 0x402a10a8\n",
       "  LogSigmoid : table: 0x41e2c730\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  Sum : table: 0x41a1c128\n",
       "  SoftSign : table: 0x41e341d0\n",
       "  CSubTable : table: 0x41e71808\n",
       "  SpatialUpSamplingNearest : table: 0x402b5c30\n",
       "  Mul : table: 0x41e75f68\n",
       "  AddConstant : table: 0x4157fa28\n",
       "  Tanh : table: 0x41e353c0\n",
       "  Replicate : table: 0x41e6b110\n",
       "  BatchNormalization : table: 0x41e6d660\n",
       "  Select : table: 0x40d556a8\n",
       "  SpatialLPPooling : table: 0x4079e648\n",
       "  Sigmoid : table: 0x41e2f018\n",
       "  GradientReversal : table: 0x40d60328\n",
       "  SpatialConvolution : table: 0x41790270\n",
       "  Criterion : table: 0x418e2318\n",
       "  SpatialConvolutionMap : table: 0x407926a0\n",
       "  ReLU : table: 0x4177f108\n",
       "  SpatialFullConvolutionMap : table: 0x4078a110\n",
       "  tables : \n",
       "    {\n",
       "      full : function: 0x40792768\n",
       "      oneToOne : function: 0x40792788\n",
       "      random : function: 0x407927a8\n",
       "    }\n",
       "  SpatialMaxUnpooling : table: 0x407990a0\n",
       "  SpatialFullConvolution : table: 0x41e2b1f8\n",
       "  Transpose : table: 0x41f247e8\n",
       "  RReLU : table: 0x41785518\n",
       "  SpatialZeroPadding : table: 0x402b05b0\n",
       "  Min : table: 0x40d5f9e8\n",
       "  Narrow : table: 0x419a40e8\n",
       "  Normalize : table: 0x407f5d58\n",
       "  ParallelTable : table: 0x407072e0\n",
       "  SpatialSoftMax : table: 0x417838c8\n",
       "  SpatialFractionalMaxPooling : table: 0x4079cc00\n",
       "}\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer:train(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. Test the network, print accuracy__\n",
    "\n",
    "We have trained the network for 2 passes over the training dataset.  \n",
    "But we need to check if the network has learnt anything at all.  \n",
    "We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, first step. Let us display an image from the test set to get familiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classes[testset.label[100]])\n",
    "itorch.image(testset.data[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are done with that, let us normalize the test data with the mean and standard-deviation from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testset.data = testset.data:double()   -- convert from Byte tensor to Double tensor\n",
    "for i=1,3 do -- over each image channel\n",
    "    testset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction    \n",
    "    testset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- for fun, print the mean and standard-deviation of example-100\n",
    "horse = testset.data[100]\n",
    "print(horse:mean(), horse:std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let us see what the neural network thinks these examples above are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classes[testset.label[100]])\n",
    "itorch.image(testset.data[100])\n",
    "predicted = net:forward(testset.data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- the output of the network is Log-Probabilities. To convert them to probabilities, you have to take e^x \n",
    "print(predicted:exp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the network predictions. The network assigned a probability to each classes, given the image.\n",
    "\n",
    "To make it clearer, let us tag each probability with it's class-name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i=1,predicted:size(1) do\n",
    "    print(classes[i], predicted[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, fine. One single example sucked, but how many in total seem to be correct over the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i=1,10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(correct, 100*correct/10000 .. ' % ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks waaay better than chance, which is 10% accuracy (randomly picking a class out of 10 classes). Seems like the network learnt something.\n",
    "\n",
    "Hmmm, what are the classes that performed well, and the classes that did not perform well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_performance = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n",
    "for i=1,10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        class_performance[groundtruth] = class_performance[groundtruth] + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i=1,#classes do\n",
    "    print(classes[i], 100*class_performance[i]/1000 .. ' %')\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so what next? How do we run this neural network on GPUs?\n",
    "\n",
    "#### cunn: neural networks on GPUs using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'cunn';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is pretty simple. Take a neural network, and transfer it over to GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = net:cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, transfer the criterion to GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = criterion:cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset.data = trainset.data:cuda()\n",
    "trainset.label = trainset.label:cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's train on GPU :) #sosimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 5 -- just do 5 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer:train(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why dont I notice MASSIVE speedup compared to CPU?\n",
    "Because your network is realllly small. \n",
    "\n",
    "**Exercise:** Try increasing the size of your network (argument 1 and 2 of nn.SpatialConvolution(...), see what kind of speedup you get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals achieved:**\n",
    "* Understand torch and the neural networks package at a high-level.\n",
    "* Train a small neural network on CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where do I go next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build crazy graphs of networks: https://github.com/torch/nngraph\n",
    "* Train on imagenet with multiple GPUs: https://github.com/soumith/imagenet-multiGPU.torch\n",
    "* Train recurrent networks with LSTM on text: https://github.com/wojzaremba/lstm\n",
    "\n",
    "* More demos and tutorials: https://github.com/torch/torch7/wiki/Cheatsheet\n",
    "\n",
    "* Chat with developers of Torch: http://gitter.im/torch/torch7\n",
    "* Ask for help: http://groups.google.com/forum/#!forum/torch7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
