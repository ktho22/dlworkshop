{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 라이브러리 실습: Torch의 이해 및 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 실습 목표\n",
    "\n",
    "* Torch와 nn 패키지의 이해\n",
    "* 작은 Neural network 를 CPU에서 학습 및 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시작에 앞서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Torch는 `Lua` 를 사용하여 코딩함\n",
    "* `Lua`는 `Javascript`와 유사한 면을 지니며, 변수는 global이 default로, `local`이라는 키워드로 로컬변수 설정이 가능\n",
    "* 1-based indexing.\n",
    "* Function call `foo.bar()`는 Lua에서 `foo:bar()`로 쓰임\n",
    "* Python에서의 `import`, C에서 `include` 처럼 외부 라이브러리를 포함시키는 명령어는 `require`임\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lua: 기본 사용법\n",
    "#### Strings, numbers, and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = 'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b[1] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b[2] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i=1,#b do -- the # operator is the length operator in Lua\n",
    "    print(b[i]) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor(5,3) -- construct a 5x3 matrix, uninitialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.6571  0.1667  0.8858\n",
       " 0.0547  0.6048  0.4849\n",
       " 0.3794  0.5189  0.1749\n",
       " 0.8338  0.9002  0.2758\n",
       " 0.0220  0.6223  0.7457\n",
       "[torch.DoubleTensor of size 5x3]\n",
       "\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(5,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b=torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.1616  1.3225  0.6878  0.6795\n",
       " 0.7125  0.8149  0.8241  0.5996\n",
       " 0.5274  0.7661  0.6579  0.6855\n",
       " 0.9630  1.4436  1.1609  1.2946\n",
       " 0.9472  1.0081  0.9542  0.6328\n",
       "[torch.DoubleTensor of size 5x4]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- matrix-matrix multiplication: syntax 1\n",
    "a*b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.1616  1.3225  0.6878  0.6795\n",
       " 0.7125  0.8149  0.8241  0.5996\n",
       " 0.5274  0.7661  0.6579  0.6855\n",
       " 0.9630  1.4436  1.1609  1.2946\n",
       " 0.9472  1.0081  0.9542  0.6328\n",
       "[torch.DoubleTensor of size 5x4]\n",
       "\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- matrix-matrix multiplication: syntax 2\n",
    "torch.mm(a,b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- matrix-matrix multiplication: syntax 3\n",
    "c=torch.Tensor(5,4)\n",
    "c:mm(a,b) -- store the result of a*b in c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) CUDA Tensors\n",
    ":cuda function 을 통해서 변수를 GPU로 보낼 수 있음\n",
    "\n",
    "본 실습에서 주어진 환경은 CPU 기반으로 작동되지 않음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"require 'cutorch';...\"]:1: module 'cutorch' not found:\n\tno field package.preload['cutorch']\n\tno file '/root/.luarocks/share/lua/5.1/cutorch.lua'\n\tno file '/root/.luarocks/share/lua/5.1/cutorch/init.lua'\n\tno file '/root/torch/install/share/lua/5.1/cutorch.lua'\n\tno file '/root/torch/install/share/lua/5.1/cutorch/init.lua'\n\tno file './cutorch.lua'\n\tno file '/root/torch/install/share/luajit-2.1.0-beta1/cutorch.lua'\n\tno file '/usr/local/share/lua/5.1/cutorch.lua'\n\tno file '/usr/local/share/lua/5.1/cutorch/init.lua'\n\tno file '/root/torch/install/lib/cutorch.so'\n\tno file '/root/.luarocks/lib/lua/5.1/cutorch.so'\n\tno file '/root/torch/install/lib/lua/5.1/cutorch.so'\n\tno file './cutorch.so'\n\tno file '/usr/local/lib/lua/5.1/cutorch.so'\n\tno file '/usr/local/lib/lua/5.1/loadall.so'\nstack traceback:\n\t[C]: in function 'require'\n\t[string \"require 'cutorch';...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/root/torch/install/share/lua/5.1/itorch/main.lua:209: in function </root/torch/install/share/lua/5.1/itorch/main.lua:173>\n\t/root/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/root/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/root/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/root/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/root/torch/install/share/lua/5.1/itorch/main.lua:381: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406670",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"require 'cutorch';...\"]:1: module 'cutorch' not found:\n\tno field package.preload['cutorch']\n\tno file '/root/.luarocks/share/lua/5.1/cutorch.lua'\n\tno file '/root/.luarocks/share/lua/5.1/cutorch/init.lua'\n\tno file '/root/torch/install/share/lua/5.1/cutorch.lua'\n\tno file '/root/torch/install/share/lua/5.1/cutorch/init.lua'\n\tno file './cutorch.lua'\n\tno file '/root/torch/install/share/luajit-2.1.0-beta1/cutorch.lua'\n\tno file '/usr/local/share/lua/5.1/cutorch.lua'\n\tno file '/usr/local/share/lua/5.1/cutorch/init.lua'\n\tno file '/root/torch/install/lib/cutorch.so'\n\tno file '/root/.luarocks/lib/lua/5.1/cutorch.so'\n\tno file '/root/torch/install/lib/lua/5.1/cutorch.so'\n\tno file './cutorch.so'\n\tno file '/usr/local/lib/lua/5.1/cutorch.so'\n\tno file '/usr/local/lib/lua/5.1/loadall.so'\nstack traceback:\n\t[C]: in function 'require'\n\t[string \"require 'cutorch';...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/root/torch/install/share/lua/5.1/itorch/main.lua:209: in function </root/torch/install/share/lua/5.1/itorch/main.lua:173>\n\t/root/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/root/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/root/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/root/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/root/torch/install/share/lua/5.1/itorch/main.lua:381: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406670"
     ]
    }
   ],
   "source": [
    "require 'cutorch';\n",
    "a = a:cuda()\n",
    "b = b:cuda()\n",
    "c = c:cuda()\n",
    "c:mm(a,b) -- done on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Add two tensors\n",
    "https://github.com/torch/torch7/blob/master/doc/maths.md#res-torchaddres-tensor1-tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function addTensors(a,b)\n",
    "    return a --FIX ME\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1  1\n",
       " 1  1\n",
       " 1  1\n",
       " 1  1\n",
       " 1  1\n",
       "[torch.DoubleTensor of size 5x2]\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5,2)\n",
    "b = torch.Tensor(2,5):fill(4)\n",
    "print(addTensors(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예상 결과:\n",
    "\n",
    "5 5\n",
    "\n",
    "5 5\n",
    "\n",
    "5 5\n",
    "\n",
    "5 5\n",
    "\n",
    "5 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "Torch 에서 Neural Net은 `nn` 이라는 패키지를 통해서 구축함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `module`은 Neural Net을 구성하는 기본 요소로, Layer, activation 등을 정의함\n",
    "* 각 `module`은 `containers`를 이용하여 보다 복잡한 구조로 설계가 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시로, 다음과 같은 네트워크를 만들어보겠습니다.\n",
    "![LeNet](http://fastml.com/images/cifar/lenet5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위 네트워크는 Yann Lecun이 제시한 `LeNet` 이라고 불리는 네트워크로, 최근에는 `Convolutional Neural Network (CNN)` 이라는 이름으로 불림\n",
    "* 간단한 feed-forward 구조를 가지며, 입력으로 이미지를 받아 일련의 레이어들의 연산을 거친 뒤 해당 이미지가 0~9중 어떤 숫자인 지 맞추는 역할을 수행함\n",
    "* 이런 경우, `nn.Sequential`을 이용하여 여러 레이어를 묶을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lenet5\n",
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> output]\n",
       "  (1): nn.SpatialConvolution(1 -> 6, 5x5)\n",
       "  (2): nn.ReLU\n",
       "  (3): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (4): nn.SpatialConvolution(6 -> 16, 5x5)\n",
       "  (5): nn.ReLU\n",
       "  (6): nn.SpatialMaxPooling(2x2, 2,2)\n",
       "  (7): nn.View(400)\n",
       "  (8): nn.Linear(400 -> 120)\n",
       "  (9): nn.ReLU\n",
       "  (10): nn.Linear(120 -> 84)\n",
       "  (11): nn.ReLU\n",
       "  (12): nn.Linear(84 -> 10)\n",
       "  (13): nn.LogSoftMax\n",
       "}\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(1, 6, 5, 5)) -- 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems\n",
    "\n",
    "print('Lenet5\\n' .. net:__tostring());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Sequential`이외에 다른 Container 들은 다음과 같음\n",
    "![containers](https://raw.githubusercontent.com/soumith/ex/gh-pages/assets/nn_containers.png)\n",
    "\n",
    "* Torch의 강점 중 하나는 Automatic differentiation을 지원한다는 것임\n",
    "* `:forward(input)` 으로 입력에 대한 출력이 만들어지면, `:backward(input, gradient)` 가 각 neuron 에 대한 gradient를 chain rule을 이용해 계산함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = torch.rand(1,32,32) -- pass a random tensor as input to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = net:forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.1829\n",
       "-2.2303\n",
       "-2.3989\n",
       "-2.2164\n",
       "-2.3583\n",
       "-2.4214\n",
       "-2.2408\n",
       "-2.3583\n",
       "-2.3725\n",
       "-2.2789\n",
       "[torch.DoubleTensor of size 10]\n",
       "\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net:zeroGradParameters() -- zero the internal gradient buffers of the network (will come to this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradInput = net:backward(input, torch.rand(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  1\n",
       " 32\n",
       " 32\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#gradInput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion: loss function 정의하기\n",
    "\n",
    "앞서 계산한 Gradient 값은 랜덤한 숫자에 대해서 Backward 연산을 합니다.\n",
    "\n",
    "이제는, 정해진 목표에 기반해 네트워크를 학습하는 방법에 대해 알아보겠습니다. 이 때, 정해진 목표를 측정하는 방법을 __loss function__ 이라고 합니다.\n",
    "\n",
    "__loss function__은 주어진 입력이 모델을 통과해서 나온 결과와 정답을 비교하여 측정하게 되며, 네트워크는 이를 줄여나가는 방향으로 학습하게 됩니다. \n",
    "\n",
    "Torch 에서는 loss function 을 이용해 neural network 를 학습할 때 automatic differentiation을 쓰고, 이는 `forward(input, target)`, `backward(input, target)`을 통해서 구현됩니다. 아래에서 loss function 을 이용한 예시를 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion() -- a negative log-likelihood criterion for multi-class classification\n",
    "criterion:forward(output, 3) -- let's say the groundtruth was class number: 3\n",
    "gradients = criterion:backward(output, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,.,.) = \n",
       " Columns 1 to 9\n",
       " 0.001 *\n",
       "   0.0000  0.0291  0.0371  0.0183  0.1086  0.1493 -0.0134  0.2299  0.2806\n",
       "   0.0000  0.0089  0.0428 -0.0107 -0.0140  0.1725  0.1913 -0.5681  0.2317\n",
       "   0.0694  0.1314  0.0042  0.2256  0.5145  0.0254 -0.0771 -0.4593  0.0086\n",
       "  -0.0914 -0.1123 -0.0714 -0.0739  0.2267  0.1155 -0.4630 -0.3367  0.6342\n",
       "  -0.1163 -0.2187  0.1422  0.0062  0.2223  0.2562  0.5974  0.5633  0.0321\n",
       "  -0.1753 -0.0345  0.2873  0.0723  0.3194  0.4790  0.2372  0.0729  0.7507\n",
       "  -0.0208 -0.1115  0.4422  0.1982  0.0380 -0.2949  0.2031  0.2621 -1.1014\n",
       "   0.0479 -0.0935 -0.0459 -0.2865 -1.2765 -0.8246  0.0526 -0.3158  0.6791\n",
       "  -0.2674 -0.6385 -0.3457 -1.1053 -0.9820  0.1198 -0.2533 -0.2498 -0.3046\n",
       "   0.1591 -0.2521  0.1485  0.6525 -0.1052  0.5137  1.6417  0.7247  0.5735\n",
       "   0.0441  0.3987  0.2063 -0.3440  1.2973  1.8492 -0.6270 -1.5242 -0.2255\n",
       "   0.2003 -0.1226  0.6185 -0.2960  0.2886  0.0261 -0.9714 -1.9248 -0.4643\n",
       "   0.1717  0.1578 -0.1734 -0.8594  0.6032  0.2577  0.0569  0.4985  0.1514\n",
       "   0.1753  0.6096  0.3933 -0.8005 -0.0008 -0.6205  0.0406  0.5346 -0.0785\n",
       "   0.3829 -0.1259 -0.1200  0.3041  0.9981  0.2182  0.6172 -1.2479 -0.3890\n",
       "   0.1099  0.1240 -0.0018  0.3771  0.0910  0.2893  1.6647  0.8171 -1.5763\n",
       "  -0.0421  0.1846  0.0643 -0.0076 -0.2562  0.1284 -0.6763 -0.6058  1.4445\n",
       "  -0.1128  0.0598 -0.4587 -0.6399 -0.8048  0.1225 -1.0384 -0.3243 -1.8814\n",
       "  -0.5434 -0.1062 -0.1553 -1.2160 -0.8855 -1.7310 -2.8158 -1.2058 -0.8519\n",
       "   0.3603  0.2777 -0.0911  0.5592 -0.0089 -0.0830  0.8511  0.8309 -0.1452\n",
       "  -0.1489  0.4083  0.2148 -0.5002  0.4926 -0.8250 -0.2984 -2.1025  0.7024\n",
       "  -0.1952 -0.6028 -0.2267 -0.5545 -0.4772 -0.2132 -1.9088 -1.6963 -0.7976\n",
       "  -0.3866 -0.2940  0.3055 -0.0077 -0.0444 -0.7067 -0.5456 -1.1603 -0.8175\n",
       "   0.1383 -0.4680 -0.0664  0.0910  1.2735  0.0266  0.7598  0.0263  0.7510\n",
       "  -0.1314  0.2104  0.2566 -0.5047 -0.3813  0.0409  0.6150  0.0259 -1.4494\n",
       "   0.2570  0.2889 -0.6869  0.5927  0.9726  0.2717  0.2226  0.9573  0.8189\n",
       "   0.1843  0.0490 -0.8480 -0.2764 -1.1331  0.1044  0.1873 -1.0881  0.4326\n",
       "   0.0096 -0.1597 -0.2077  0.0033  0.2876 -0.4980 -0.6025  0.3295  2.0604\n",
       "   0.0505  0.0319 -0.2010 -0.0191  0.4065  0.5920  0.0471  0.7327  1.1832\n",
       "  -0.0145  0.1808 -0.1555 -0.4744  0.5430  0.3878  0.3109  0.1364  0.0933\n",
       "   0.0316  0.1480 -0.0495 -0.0677  0.5692  0.1865  0.1292  0.1047  0.1654\n",
       "   0.0000  0.0000  0.0000  0.0122  0.1217 -0.2774 -0.5704 -0.0245  0.2107\n",
       "\n",
       "Columns 10 to 18\n",
       " 0.001 *\n",
       "   0.2833  0.1780  0.0201  0.4812  0.1233  0.0828 -0.1598  0.3080  0.0642\n",
       "  -0.2786  0.1426  0.0052 -0.2812  0.0165 -0.0380  0.5762  0.2647  0.8127\n",
       "   0.2197 -0.5830 -0.3667  0.2016  0.3770 -0.3553  0.1884  0.1707  0.0314\n",
       "  -0.4929  0.2361  0.5661  1.7687  1.2670  0.6879  0.1766  0.4073 -0.3614\n",
       "  -0.1142  0.7655 -0.4516  1.7292  0.6445 -0.7141  0.5937  0.1637 -0.2643\n",
       "  -0.6484 -0.2044  0.5751 -0.9506 -0.8203  0.7819 -1.0961 -1.0905  0.2867\n",
       "   0.0443 -1.0889  0.1701 -0.6632 -0.9419 -0.6420  0.4012  0.6898 -0.9307\n",
       "  -0.3917  1.0106  0.5931  0.5622 -0.0328  0.9708  1.3312  0.6938 -0.0456\n",
       "   0.6136  1.5757  0.5168  0.0982 -0.7276 -0.4283  0.2505 -0.5443 -1.6322\n",
       "  -0.5821 -1.2879 -1.5245 -1.1983  0.2563  0.6329  0.8655 -1.3653  0.2559\n",
       "  -0.7578  1.8734 -0.2258  0.7084  0.8952  1.0565  0.4343  1.2138  0.9807\n",
       "   0.3354  1.3132 -0.8221 -0.5776  0.5020 -0.4213  0.1956  1.5114  0.7435\n",
       "  -0.7117  1.3651  0.1040 -1.2836 -0.1602 -1.0303 -0.0355  0.5922 -1.8204\n",
       "  -0.0281 -0.1123 -2.0095 -2.1221 -0.8689  1.6348  0.2081 -2.4449 -2.7207\n",
       "  -0.7665  0.3110  1.8775  0.1831  0.9195  0.5633  0.4635  0.6543  0.2560\n",
       "   1.6176  1.4271 -1.5039  1.4884 -0.3908 -0.9647  0.3312  0.9065 -0.7996\n",
       "   0.3047 -0.7340  0.3540  1.6164  0.2185  0.4664 -0.2313  0.7533 -0.2114\n",
       "  -0.9257 -1.5581 -0.8147 -0.1303 -0.1478  0.3810 -0.8830  0.8577 -0.4630\n",
       "   1.8682  0.5262  2.2380 -0.1438  0.3716  1.4416  1.0053  0.9043  0.1234\n",
       "   1.2171  0.2764 -0.1220  1.8890  0.4648 -0.4491  1.3621  0.3715  0.1414\n",
       "  -0.5233  0.3843 -0.2289 -0.0470 -0.3727 -1.5567  0.9613  1.1064  0.0378\n",
       "   0.2536 -0.7777 -1.7831 -0.3970  1.0914 -0.7118  0.3236  1.1571 -0.5152\n",
       "   0.5262  1.0839  1.4774 -0.4411 -0."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0707  0.4495  1.1701  0.3510 -0.9234\n",
       "  -0.8260  0.0989 -0.7745 -0.8186  1.8737 -1.0863  0.5746 -0.9142 -0.2036\n",
       "  -0.2927  0.6700  1.4890 -0.3628  0.9798 -2.0676  0.9222  0.1318 -0.8615\n",
       "  -1.9893  0.2233 -0.9961  0.0589  2.1187 -1.3652  0.8751  0.0650 -0.1673\n",
       "   1.6509  0.0718 -1.2880  0.1548  1.1879  0.1907  0.2835  0.4890  1.2773\n",
       "   0.0051 -0.2732  0.1568  0.3367 -0.1594  0.6350  1.5084 -0.9498 -0.2570\n",
       "   0.5263 -0.6826 -0.7995  1.2223  0.5330 -0.1184 -0.0877 -0.6064 -0.9064\n",
       "   0.0297 -0.3268 -0.6540 -0.6925  0.1483 -0.0695 -0.8240 -0.1422  0.2905\n",
       "  -0.3318  0.2102 -0.0185 -0.1207  0.0641  0.3514 -0.1259  0.4044  0.2492\n",
       "  -0.5096 -0.3012  0.5028  0.0709 -0.2461  0.5003  0.1534 -0.2304 -0.1150\n",
       "\n",
       "Columns 19 to 27\n",
       " 0.001 *\n",
       "   0.0984 -0.0785  0.0044 -0.0466 -0.0407 -0.0940 -0.0259  0.1236  0.0185\n",
       "  -0.3696 -0.1641  0.0082  0.3497 -0.1876 -0.1073 -0.1664  0.0773 -0.1996\n",
       "  -0.0962  0.2621 -0.2432  0.1952 -0.2940 -0.0807 -0.3321 -0.0414 -0.2135\n",
       "   0.1693 -0.0649 -0.0228  0.1715 -0.2422 -0.1559  0.2192  0.1200 -0.0056\n",
       "   0.3610  0.0852  0.0200 -0.3747 -0.1300 -0.4358  0.2300  0.2978 -0.1007\n",
       "  -1.4048  0.0820 -0.1310  0.1180 -0.3922 -0.0965  0.1239  0.3623  0.3683\n",
       "   0.8517  1.2191 -0.3432  1.2790  1.0335 -0.6906 -0.1142 -0.5445 -0.4498\n",
       "   1.1811 -0.4306  1.5582  1.4746 -0.4788 -0.0959 -0.6057  0.2211  0.5114\n",
       "  -1.6989  0.1557 -0.9255  0.8641 -0.7318 -0.1110  0.4923  0.8620 -0.0209\n",
       "   0.2971 -0.3669  1.2313 -0.2459  1.3528 -0.0844  1.0357  0.1301 -0.2211\n",
       "   1.0689  1.7821  0.0860  1.3444  0.3926 -0.2198  0.7332 -0.5230 -0.2442\n",
       "   0.2753 -0.1021  0.7794  1.9034  2.0954 -1.1919  1.6786  1.1011 -0.2675\n",
       "  -3.4711  1.2069  0.4279 -0.1138  1.0782  1.2413 -0.5821  0.9468  0.3631\n",
       "  -0.3077  0.9937  1.2334 -0.2031 -1.1437 -1.6013  0.1198  1.5368  0.7723\n",
       "   2.4232 -1.2017 -0.7116 -1.1667 -2.1658 -0.7862  0.8162  0.1485  0.0268\n",
       "  -0.7286 -3.3108  0.2212  1.2621 -0.2811 -0.3607 -0.6182 -0.5041 -0.4325\n",
       "  -1.4675 -0.7467 -0.2369 -2.3683  0.0154  0.6526 -0.8014 -1.7326 -0.2547\n",
       "  -0.6060  1.0656  0.4114  0.2897  1.7542 -0.3185  0.4304  0.2980  0.9343\n",
       "   1.7835 -0.9174 -1.5345 -0.2708  0.9257 -0.3492  0.2643 -1.4582  0.2176\n",
       "  -0.8531  0.7141  0.0654 -0.0759  1.2251 -0.7596 -0.0598  0.8080  1.3347\n",
       "   0.4458  1.7224  0.5819  1.0326  1.0752 -0.1255 -0.8025 -0.5022  0.5345\n",
       "  -0.7467  0.8271  0.2689 -0.6617  0.0809 -1.0265  0.9462 -0.0300 -1.8323\n",
       "   0.4550 -0.1359 -0.1960 -0.6638 -0.1834  0.1940 -0.1742 -0.4373 -1.0170\n",
       "  -2.0248  0.0889 -0.6992  1.2911  2.2482  0.4193  0.8557  0.3819 -0.1021\n",
       "   0.6285  0.9453 -0.6441 -0.4794  0.8159  0.3671  0.3526  0.6537  0.7134\n",
       "  -0.3458  0.1017  0.0346 -0.2508 -0.3015  0.0615  0.2419 -0.2281 -0.3455\n",
       "   0.5221  0.6978  0.0084 -0.8360  0.3551 -0.1421 -0.1152 -0.9183 -0.1109\n",
       "   1.0750  0.0626 -0.3924  0.7536  0.1627 -0.1587 -0.5839 -0.1059  0.1289\n",
       "  -0.2066 -0.5929  0.1234 -0.3044 -0.0975 -0.0193  0.8381  0.3062  0.1833\n",
       "   0.3443  0.3280  0.4064 -0.2538  0.3189 -0.0615  0.2746 -0.0056  0.2110\n",
       "  -0.0279 -0.1301 -0.1597 -0.0252  0.0998 -0.0871  0.2549  0.1803  0.0300\n",
       "   0.4752  0.0512 -0.0763 -0.0025  0.2104  0.0664 -0.0349  0.1125  0.1759\n",
       "\n",
       "Columns 28 to 32\n",
       " 0.001 *\n",
       "  -0.0315  0.0223  0.0278 -0.0063  0.0123\n",
       "   0.0579  0.0262 -0.0471 -0.0002  0.0376\n",
       "   0.0832 -0.0761  0.1780  0.1571 -0.0750\n",
       "  -0.3379 -0.1519 -0.0771 -0.2408  0.0311\n",
       "  -0.0873  0.0098  0.2448  0.2294 -0.1284\n",
       "  -1.1172  0.3134 -0.0810 -0.1887 -0.0202\n",
       "  -0.2666 -0.1308  0.0336  0.0779 -0.1141\n",
       "  -0.9420  0.2578  0.3669 -0.3766 -0.3032\n",
       "  -0.6565  0.1247  0.0673 -0.0263 -0.1475\n",
       "   0.3230 -0.3503 -0.3332 -0.2598  0.0233\n",
       "  -0.4861 -0.0827  0.0288 -0.1057 -0.0211\n",
       "  -0.4580  0.2893 -0.1626 -0.4349 -0.1242\n",
       "  -0.5590  0.2774  1.0958  0.0879  0.1604\n",
       "   0.1339  0.8207 -0.5435  0.2851 -0.0009\n",
       "  -0.3308  0.1452  0.7729  0.0958  0.0567\n",
       "   0.3449 -0.4194  0.2225  0.1986  0.1496\n",
       "  -0.2032 -0.1318 -0.1821 -0.4963  0.1136\n",
       "   1.7448  0.0257  0.4316 -0.3618  0.1913\n",
       "  -0.7094  0.3131  0.4616 -0.0556  0.4318\n",
       "   0.3729  1.3038 -0.4367  0.3249 -0.0943\n",
       "  -0.2052 -0.8170 -0.8132 -0.3589  0.2985\n",
       "  -1.2031 -0.1065 -0.6100 -0.3716 -0.4047\n",
       "  -0.5008 -0.9150 -1.3380  0.0473 -0.1088\n",
       "   0."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8477 -0.0621 -0.5562  0.4839  0.0504\n",
       "   0.3001  0.2313 -0.1023 -0.1863 -0.1403\n",
       "  -0.0212 -0.0045  0.1505 -0.1419 -0.0741\n",
       "  -0.1642  0.1866  0.1029 -0.0739 -0.0760\n",
       "  -0.2734  0.4564 -0.0892 -0.0021  0.0455\n",
       "   0.2106  0.1346 -0.0467 -0.0794 -0.0291\n",
       "   0.0764  0.1396 -0.2192 -0.1821  0.0357\n",
       "   0.0130 -0.0644  0.0196  0.0595 -0.0848\n",
       "  -0.1196 -0.2022  0.0390 -0.0442 -0.0630\n",
       "[torch.DoubleTensor of size 1x32x32]\n",
       "\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradInput = net:backward(input, gradients)\n",
    "print(gradInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 현재까지 배운 내용\n",
    "* 하나의 네트워크는 다양한 컨테이너 및 모듈로 생성 가능하며, 사용하는 컨테이너/모듈에 따라 연산도 다양해집니다.\n",
    "* 네트워크는 :forward 로 입력을 받아 출력을 내보냅니다.\n",
    "* Criterion은 네트워크의 loss를 의미하며, 해당 loss를 줄이는 방향으로 gradient 를 계산합니다. \n",
    "* Criterion으로부터 계산한 gradient를 이용해 net:backward를 이용해 네트워크의 파라미터들을 수정합니다. \n",
    "\n",
    "##### Missing details\n",
    "* 특정 레이어는 학습 가능한 파라미터를 가지고 있지 않습니다.\n",
    "* 학습되는 파라미터는 주로 .weight (혹은 .bias) 라는 필드에 값이 저장되어 있으며, pooling layer의 경우에는 따로 파라미터를 학습하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,1,.,.) = \n",
       " -0.3884 -0.1866\n",
       " -0.0250  0.2955\n",
       "\n",
       "(2,1,.,.) = \n",
       " -0.4183  0.4169\n",
       " -0.0607  0.4456\n",
       "\n",
       "(3,1,.,.) = \n",
       "  0.1390  0.1635\n",
       " -0.3762  0.2553\n",
       "[torch.DoubleTensor of size 3x1x2x2]\n",
       "\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.SpatialConvolution(1,3,2,2) -- learn 3 2x2 kernels\n",
    "print(m.weight) -- initially, the weights are randomly initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1599\n",
       "-0.4654\n",
       "-0.3679\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m.bias) -- The operation in a convolution layer is: output = convolution(input,weight) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이처럼, 접근 가능한 필드 중에서 학습되는 또 다른 필드는 gradWeight와 gradBisa가 있슨비다.\n",
    "gradWeight는 각 레이어 내의 weight에 대한 gradient가, gradBias는 레이어 내의 bias에 대한 gradient가 저장되는 곳입니다.\n",
    "\n",
    "#### Training the network\n",
    "\n",
    "이제부터 네트워크를 직접 학습해보겠습니다. 이는 아래의 식을 따라 파라미터를 변경하는 것을 의미합니다.\n",
    "> weight = weight + learningRate * gradWeight [equation 1]\n",
    "\n",
    "위 업데이트는 네트워크의 파라미터를 바꿔 loss를 줄여나가는 역할을 하게 됩니다. 본 실습에서 쓰이는 방법은 Stochastic Gradient Descent (SGD) 입니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 Equation 1을 수행하기 위해서는 SGD를 수행하는 nn 내의 모듈을 이용해야 합니다. 이는 [__nn.StochasticGradient__] 으로 정의되어 있습니다. (https://github.com/torch/nn/blob/master/doc/training.md#stochasticgradientmodule-criterion).\n",
    "\n",
    "위 모듈은 :train(dataset)이라는 함수를 가지고 있어 주어진 dataset을 이용해 네트워크를 학습할 수 있습니다. 자세한 사용법은 아래에서 설명하겠습니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about data?\n",
    "\n",
    "이제 직접 네트워크를 학습하기에 앞서, 데이터를 어떻게 네트워크에 넣는 지에 대해서 설명하겠습니다. 이미지, 텍스트, 오디오, 비디오 등 다양한 형식의 입력이 가능하며, 이는 예를 들어 [__image.load__](https://github.com/torch/image#res-imageloadfilename-depth-tensortype), [__audio.load__](https://github.com/soumith/lua---audio#usage) 등이 이용될 수 있습니다. 보다 자세한 Data I/O에 관련해서는 https://github.com/torch/torch7/wiki/Cheatsheet#data-formats 페이지를 참고하시면 도움을 얻을 수 있습니다. \n",
    "\n",
    "본 실습을 위해서 이용되는 데이터셋은 CIFAR-10 이라는 데이터로, 다음과 같은 class를 가지고 있습니다. 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'.  \n",
    "\n",
    "각 이미지는 3x32x32의 사이즈를 지니며, 즉, RGB 의 3채널의 32x32 pixels 크기의 이미지를 의미합니다.\n",
    "![CIFAR-10 image](https://raw.githubusercontent.com/soumith/ex/gh-pages/assets/cifar10.png)\n",
    "\n",
    "해당 데이터셋은  50,000의 트레이닝 이미지와 10,000 장의 테스트 이미지를 포함하고 있습니다.\n",
    "\n",
    "__딥러닝을 이용한 데이터 분석 5 단계__\n",
    "1. 데이터 Load 및 normalization\n",
    "2. 모델 정의 (e.g. DNN, CNN, ...)\n",
    "3. Loss function 정의 (e.g. Euclidean distance, NLL, ...)\n",
    "4. 트레이닝 데이터로 모델 학습하기\n",
    "5. 테스트 데이터로 모델 테스트하기\n",
    "\n",
    "__1. 데이터 Load 및 normalization__\n",
    "\n",
    "앞서 말한 CIFAR-10을 직접 불러오겠습니다. 이는 사전에 다운로드 받아져있을 것이며, 아닌 경우 자동으로 다운 받아집니다. (다운을 새로 받는 경우, 몇 분의 시간이 소요됩니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'paths'\n",
    "if (not paths.filep(\"cifar10torchsmall.zip\")) then\n",
    "    os.execute('wget -c https://s3.amazonaws.com/torch7/data/cifar10torchsmall.zip')\n",
    "    os.execute('unzip cifar10torchsmall.zip')\n",
    "end\n",
    "trainset = torch.load('cifar10-train.t7')\n",
    "testset = torch.load('cifar10-test.t7')\n",
    "classes = {'airplane', 'automobile', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  data : ByteTensor - size: 10000x3x32x32\n",
       "  label : ByteTensor - size: 10000\n",
       "}\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10000\n",
       "     3\n",
       "    32\n",
       "    32\n",
       "[torch.LongStorage of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#trainset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10 내의 이미지를 프린트해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "automobile\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itorch.image(trainset.data[100]) -- display the 100-th image in dataset. You can freely change this.\n",
    "print(classes[trainset.label[100]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 언급한 __nn.StochasticGradient__ 에 이용되기 위해서는, dataset에 다음과 같은 가공을 해야 합니다. [documentation](https://github.com/torch/nn/blob/master/doc/training.md#traindataset).\n",
    "1. 데이터셋이 :size() 함수를 지니고 있어야 합니다. \n",
    "2. 데이터셋은 [i] 로 indexing이 가능해야 합니다. \n",
    "\n",
    "위 두 사항은 다음과 같이 진행함으로 데이터셋을 변형할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- ignore setmetatable for now, it is a feature beyond the scope of this tutorial. It sets the index operator.\n",
    "setmetatable(trainset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.label[i]} \n",
    "                end}\n",
    ");\n",
    "trainset.data = trainset.data:double() -- convert the data from a ByteTensor to a DoubleTensor.\n",
    "\n",
    "function trainset:size() \n",
    "    return self.data:size(1) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000\t\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainset:size()) -- just to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 3x32x32\n",
       "  2 : 2\n",
       "}\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(trainset[33]) -- load sample number 33.\n",
    "itorch.image(trainset[33][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__이제 주어진 데이터를 normalization을 해야 합니다. 일반적으로 많이 쓰이는 방법은 zero mean unit variance 로, 말 그대로 주어진 데이터의 mean을 0으로 맞추고  stdev을 1로 조정하는 것입니다. __\n",
    "\n",
    "위 normalization을 하기에 앞서, tensor variable을 indexing 하는 방법에 대해서 간략히 소개하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redChannel = trainset.data[{ {}, {1}, {}, {}  }] -- this picks {all images, 1st channel, all vertical pixels, all horizontal pixels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10000\n",
       "     1\n",
       "    32\n",
       "    32\n",
       "[torch.LongStorage of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#redChannel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 예제에서, trainset.data 를 [{}] 로 indexing 하기 시작했으며, {}는 모든 elements, {i}는 i i 인덱스를 추출하는 것을 의미합니다. range를 indexing 하기 위해서는 {i1, i2} (where i2>i1) 처럼 작성하면 되며 이 경우 i1 부터 i2 까지의 elements를 반환합니다. \n",
    "\n",
    "__연습문제: 데이터의 150번째부터 300번째까지 데이터를 추출하시오.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- TODO: fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 위에서 말한 zero mean unit variance normalization을 수행하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Channel 1, Mean: 125.83175029297\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 1, Standard Deviation: 63.143400842609\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 2, Mean: 123.26066621094\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 2, Standard Deviation: 62.369209019002\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 3, Mean: 114.03068681641\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 3, Standard Deviation: 66.965808411114\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = {} -- store the mean, to normalize the test set in the future\n",
    "stdv  = {} -- store the standard-deviation for the future\n",
    "for i=1,3 do -- over each image channel\n",
    "    mean[i] = trainset.data[{ {}, {i}, {}, {}  }]:mean() -- mean estimation\n",
    "    print('Channel ' .. i .. ', Mean: ' .. mean[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction\n",
    "    \n",
    "    stdv[i] = trainset.data[{ {}, {i}, {}, {}  }]:std() -- std estimation\n",
    "    print('Channel ' .. i .. ', Standard Deviation: ' .. stdv[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ 2. 모델 정의하기__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제:** 위의 __Neural Networks__ 섹션에서 코드를 가져와 3 채널 이미지를 입력으로 하는 네트워크를 설계해보세요. \n",
    "Hint: 첫번째 레이어만 수정하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(3, 6, 5, 5)) -- 3 input image channels, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Loss function 정의하기__\n",
    "\n",
    "본 예제에서는 Log-likelihood classification loss를 사용하겠습니다. Log-likelihood loss는 대부분의 classificatin에 통용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. 네트워크 학습하기__\n",
    "\n",
    "먼저, __nn.StochasticGradient__ 객체를 정의하겠습니다. 그 후에 생성한 객체의 __:train__ function에 앞서 정의한 dataset을 입력으로 넣어 학습을 진행하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 5 -- just do 5 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer:train(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. 학습된 네트워크 테스트하기__\n",
    "\n",
    "축하합니다! 네트워크를 성공적으로 학습하셨습니다.\n",
    "\n",
    "이제 학습한 네트워크가 테스트 데이터 (학습 때 쓰이지 않은, 모델이 처음 보는 데이터)에 대해서도 좋은 성능을 낼 수 있는 지 평가해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classes[testset.label[100]])\n",
    "itorch.image(testset.data[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트레이닝 데이터에서 해주었던 것처럼, testset의 데이터를 normalization 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testset.data = testset.data:double()   -- convert from Byte tensor to Double tensor\n",
    "for i=1,3 do -- over each image channel\n",
    "    testset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction    \n",
    "    testset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- for fun, print the mean and standard-deviation of example-100\n",
    "horse = testset.data[100]\n",
    "print(horse:mean(), horse:std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로, 학습한 네트워크에 테스트 데이터를 입력으로 하여 예측 결과를 출력해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classes[testset.label[100]])\n",
    "itorch.image(testset.data[100])\n",
    "predicted = net:forward(testset.data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- the output of the network is Log-Probabilities. To convert them to probabilities, you have to take e^x \n",
    "print(predicted:exp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력된 결과로부터 네트워크가 각 클래스에 대해 예측한 확률 값을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i=1,predicted:size(1) do\n",
    "    print(classes[i], predicted[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 하나의 데이터가 아니라 테스트셋의 모든 이미지를 입력으로 하여 전체 정답율을 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i=1,10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(correct, 100*correct/10000 .. ' % ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10개의 클래스가 있다는 상황에서, random guess를 하면 10%의 성능이 나온다는 것을 감안하면 위의 성능은 네트워크가 `데이터와 레이블 사이의 관계`를 학습이 되었다는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_performance = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n",
    "for i=1,10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        class_performance[groundtruth] = class_performance[groundtruth] + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i=1,#classes do\n",
    "    print(classes[i], 100*class_performance[i]/1000 .. ' %')\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__이제 딥러닝을 이용해 데이터 분석 5단계를 종료했습니다.__\n",
    "\n",
    "1. 데이터 Load 및 normalization\n",
    "2. 모델 정의 (e.g. DNN, CNN, ...)\n",
    "3. Loss function 정의 (e.g. Euclidean distance, NLL, ...)\n",
    "4. 트레이닝 데이터로 모델 학습하기\n",
    "5. 테스트 데이터로 모델 테스트하기\n",
    "\n",
    "아래부터는 gpu enable 상태로 빌드된 Torch에서 이용이 가능합니다.\n",
    "\n",
    "#### cunn: neural networks on GPUs using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'cunn';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 cpu에서 정의된 net을 :cuda() 를 이용해 gpu에 올립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = net:cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마찬가지로, criterion 또한 gpu에 올립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = criterion:cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 또한 gpu에 올립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset.data = trainset.data:cuda()\n",
    "trainset.label = trainset.label:cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 앞서 cpu에서 한 것과 같이 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 5 -- just do 5 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer:train(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크가 작을수록 cpu와 gpu의 성능 차이가 크지 않습니다. 성능 차이를 확인하기 위해선 보다 큰 네트워크를 이용해 실험을 진행하면 이를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 실습 목표 (recap)\n",
    "\n",
    "* Torch와 nn 패키지의 이해\n",
    "* 작은 Neural network 를 CPU에서 학습 및 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다음 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build crazy graphs of networks: https://github.com/torch/nngraph\n",
    "* Train on imagenet with multiple GPUs: https://github.com/soumith/imagenet-multiGPU.torch\n",
    "* Train recurrent networks with LSTM on text: https://github.com/wojzaremba/lstm\n",
    "\n",
    "* More demos and tutorials: https://github.com/torch/torch7/wiki/Cheatsheet\n",
    "\n",
    "* Chat with developers of Torch: http://gitter.im/torch/torch7\n",
    "* Ask for help: http://groups.google.com/forum/#!forum/torch7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
